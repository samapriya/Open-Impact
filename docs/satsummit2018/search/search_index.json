{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ARD analysis in Python Google Earth Engine The Planet Story With mission one completed Planet has the capability of mapping the entire planet every single day. We are trying to ask the harder question, the ones that are yet to be asked and answered. For now this notion of building a queryable earth as mission two , comes from our passion to look and to search for things. While getting imagery became critically important , the delivery method lead to questions about platforms for analysis. Mission one further meant that you would be able to analyze time series datasets over weekly and bi weekly periods and understand questions that require dynamic analysis such as vegetation patterns, climate variability and changes in hydrological cycles. It generated the single largest trove of high frequency dataset in existence with an unprecedented cadence. You can read more about efforts to create Analysis Ready Data or have at it with the defintion by Chris Holmes and offcourse dive into efforts with the Spatio Temporal Asset Catalog(STAC) Planet by the numbers from Will Marshall\u2019s post \u00a9 Planet Labs Python and Jupyter Notebooks for Remote Sensing All good data needs to be analyzed using tools and while there can be many ways of doing that the two primary ways of thinking about is bringing data to the algorithms and sending algorithm to the data. In our current setup we look at both with apporaches. Within the python environment we bring the data home, download it and setup programs to tease out as much as we can from them. The benefit of this method is probably that both the source and end result resides on your machine and you can be offline once you have the data and are just looking at analysis. Using a jupyter notebook apporach gives the user enough in terms of creating a repetable workflow ready to be shared with other users. The challenge comes when you want to scale this to a thousand or more images and running complex functions which requires more power. Google Earth Engine for browser Based Remote Sensing With the need to handle such global-scale and often massive data sets, Google was already building and hosting a platform called Google Earth Engine(GEE) designed to analyze geo-spatial data. Google Earth Engine is a cloud based analysis platform that allows for an indexable and queriable raster and vector environment while including and expanding on raster capabilities. It allows for users to perform large scale analysis on large scale datasets such as Planet's very own. You can read more about the Google Earth Engine platform here . I like to tell people that Google Earth Engine does browser based remote sensing , because all you need is an active internet connection and a browser to run this. To bring us to a fair playing field when it comes to analyzing and repeating data analysis.","title":"ARD Analysis"},{"location":"#ard-analysis-in-python-google-earth-engine","text":"","title":"ARD analysis in Python &amp; Google Earth Engine"},{"location":"#the-planet-story","text":"With mission one completed Planet has the capability of mapping the entire planet every single day. We are trying to ask the harder question, the ones that are yet to be asked and answered. For now this notion of building a queryable earth as mission two , comes from our passion to look and to search for things. While getting imagery became critically important , the delivery method lead to questions about platforms for analysis. Mission one further meant that you would be able to analyze time series datasets over weekly and bi weekly periods and understand questions that require dynamic analysis such as vegetation patterns, climate variability and changes in hydrological cycles. It generated the single largest trove of high frequency dataset in existence with an unprecedented cadence. You can read more about efforts to create Analysis Ready Data or have at it with the defintion by Chris Holmes and offcourse dive into efforts with the Spatio Temporal Asset Catalog(STAC) Planet by the numbers from Will Marshall\u2019s post \u00a9 Planet Labs","title":"The Planet Story"},{"location":"#python-and-jupyter-notebooks-for-remote-sensing","text":"All good data needs to be analyzed using tools and while there can be many ways of doing that the two primary ways of thinking about is bringing data to the algorithms and sending algorithm to the data. In our current setup we look at both with apporaches. Within the python environment we bring the data home, download it and setup programs to tease out as much as we can from them. The benefit of this method is probably that both the source and end result resides on your machine and you can be offline once you have the data and are just looking at analysis. Using a jupyter notebook apporach gives the user enough in terms of creating a repetable workflow ready to be shared with other users. The challenge comes when you want to scale this to a thousand or more images and running complex functions which requires more power.","title":"Python and Jupyter Notebooks for Remote Sensing"},{"location":"#google-earth-engine-for-browser-based-remote-sensing","text":"With the need to handle such global-scale and often massive data sets, Google was already building and hosting a platform called Google Earth Engine(GEE) designed to analyze geo-spatial data. Google Earth Engine is a cloud based analysis platform that allows for an indexable and queriable raster and vector environment while including and expanding on raster capabilities. It allows for users to perform large scale analysis on large scale datasets such as Planet's very own. You can read more about the Google Earth Engine platform here . I like to tell people that Google Earth Engine does browser based remote sensing , because all you need is an active internet connection and a browser to run this. To bring us to a fair playing field when it comes to analyzing and repeating data analysis.","title":"Google Earth Engine for browser Based Remote Sensing"},{"location":"citations/","text":"Citations Citing Planet Data From a concept in our garage, to operating the largest fleet of Earth-imaging satellites, many people have invested time and energy in developing and enabling access to Planet\u2019s unique data feed. Please cite Planet when using our imagery and tools. To cite Planet data in publications, please use the following: Planet Team (2017). Planet Application Program Interface: In Space for Life on Earth. San Francisco, CA. https://api.planet.com . Citing Tools If you use my tool and find it useful, you can cite that too Planet-GEE-Pipeline-CLI Samapriya Roy. (2018, August 8). samapriya/Planet-GEE-Pipeline-CLI: Planet-GEE-Pipeline-CLI (Version 0.3.9). Zenodo. http://doi.org/10.5281/zenodo.1341565 GEE Asset Manager Addons Samapriya Roy. (2017, November 29). samapriya/gee_asset_manager_addon: GEE Asset Manager with Addons (Version 0.2.2). Zenodo. http://doi.org/10.5281/zenodo.1068184","title":"Citations"},{"location":"citations/#citations","text":"","title":"Citations"},{"location":"citations/#citing-planet-data","text":"From a concept in our garage, to operating the largest fleet of Earth-imaging satellites, many people have invested time and energy in developing and enabling access to Planet\u2019s unique data feed. Please cite Planet when using our imagery and tools. To cite Planet data in publications, please use the following: Planet Team (2017). Planet Application Program Interface: In Space for Life on Earth. San Francisco, CA. https://api.planet.com .","title":"Citing Planet Data"},{"location":"citations/#citing-tools","text":"If you use my tool and find it useful, you can cite that too Planet-GEE-Pipeline-CLI Samapriya Roy. (2018, August 8). samapriya/Planet-GEE-Pipeline-CLI: Planet-GEE-Pipeline-CLI (Version 0.3.9). Zenodo. http://doi.org/10.5281/zenodo.1341565 GEE Asset Manager Addons Samapriya Roy. (2017, November 29). samapriya/gee_asset_manager_addon: GEE Asset Manager with Addons (Version 0.2.2). Zenodo. http://doi.org/10.5281/zenodo.1068184","title":"Citing Tools"},{"location":"contact/","text":"Contact Us Get in touch with planet Contact Page or email devex@planet.com or reach out to me PhD Candidate Intern Senior Developer Advocate at Planet Department of Geography Indiana University Bloomington, Indiana Email: samapriya.roy@gmail.com Github: samapriya.github.io","title":"Contact Us"},{"location":"contact/#contact-us","text":"Get in touch with planet Contact Page or email devex@planet.com or reach out to me PhD Candidate Intern Senior Developer Advocate at Planet Department of Geography Indiana University Bloomington, Indiana Email: samapriya.roy@gmail.com Github: samapriya.github.io","title":"Contact Us"},{"location":"planet-asset/","text":"Understand Planet Items-Assets API You can read the most updated white paper on planet products, items, assets and specifications here . While you look at these spec sheets try to understand how you would want to use the data, the purpose and scope of the question you want to answer, the size of downloads and the overall product or derivate in mind. To think of Planet products you have to understand two terms as thought they live in a hierarchy Planet Imagery Product Offerings Items and Assets Item type almost refers exclusively to a family of satellite or sensor types so PlanetScope, RapidEye, Skysat, Landsat and so on are all item types. These are model definitions based on the type of sensor you are utilizing for performing any type of analysis. Asset types are types of item derivatives or data types that you are actually utilizing for example analytic, analytic_sr, analytic_xml, visual and so on. These allow you to choose the type of actual data that you are able to download including the type and level of preprocesing that has been applied to it. For further reference on item asset relationships you can visit the docs Now the assumption here is that after you have created your account you have downloaded data either from Planet Explorer or you have been curious and looked into the data API and used the wonderful python client from planet. Incase you have not and you have python on your system, invoke the power of pip and type pip install planet There is so much more to be done using planet data using some amazing API(s) including What if you wanted to download hundreds and thousands of scenes for your analysis, the Data API will allow you to understand the backend. If you want your images to be automatically clipped to your area of interest, you can use the Clips API","title":"Planet Imagery"},{"location":"planet-asset/#understand-planet-items-assets-api","text":"You can read the most updated white paper on planet products, items, assets and specifications here . While you look at these spec sheets try to understand how you would want to use the data, the purpose and scope of the question you want to answer, the size of downloads and the overall product or derivate in mind. To think of Planet products you have to understand two terms as thought they live in a hierarchy Planet Imagery Product Offerings","title":"Understand Planet Items-Assets &amp; API"},{"location":"planet-asset/#items-and-assets","text":"Item type almost refers exclusively to a family of satellite or sensor types so PlanetScope, RapidEye, Skysat, Landsat and so on are all item types. These are model definitions based on the type of sensor you are utilizing for performing any type of analysis. Asset types are types of item derivatives or data types that you are actually utilizing for example analytic, analytic_sr, analytic_xml, visual and so on. These allow you to choose the type of actual data that you are able to download including the type and level of preprocesing that has been applied to it. For further reference on item asset relationships you can visit the docs Now the assumption here is that after you have created your account you have downloaded data either from Planet Explorer or you have been curious and looked into the data API and used the wonderful python client from planet. Incase you have not and you have python on your system, invoke the power of pip and type pip install planet There is so much more to be done using planet data using some amazing API(s) including What if you wanted to download hundreds and thousands of scenes for your analysis, the Data API will allow you to understand the backend. If you want your images to be automatically clipped to your area of interest, you can use the Clips API","title":"Items and Assets"},{"location":"planetee/","text":"Introduction As Planet achieved mission one last year it started to map the entire planet every single day. With this came the need to store tremendous amount of data, being able to serve it using our faboulous Planet Explorer and for you be able to dowload it after you created an account. While getting imagery became critically important , the delivery method lead to questions about platforms for analysis. Mission one further meant that you would be able to analyze time series datasets over weekly and bi weekly periods and understand questions that require dynamic analysis such as vegetation patters, climate variability and changes in hydrological cycles. It generated the single largest trove of high frequency dataset in existence with an unprecedented cadence or repeat over areas. Planet by the numbers from Will Marshall\u2019s post \u00a9 Planet Labs With the need to handle such global-scale and often massive data sets, Google was already building and hosting a platform called Google Earth Engine(GEE) designed to analyze geo-spatial data. Google Earth Engine is a cloud based analysis platform that allows for an indexable and queriable raster and vector environment while including and expanding on raster capabilities. It allows for users to perform large scale analysis on large scale datasets such as Planet's very own. You can read more about the Google Earth Engine platform here These set of tutorials will introduce you to methods in getting imagery onto the Google Earth Engine platform, and how do you quickly visualize and analyze the datasets with the GEE platform. With the multitude of tools and possibilities of building your own analysis tools. The first of it's kind tools will include basic methods such as 4 band operations and can include complex operations in machine learning as the platform evolves. For more information and developer guide on Google Earth Engine you can visit their developer console .","title":"Planet & Google Earth Engine"},{"location":"planetee/#introduction","text":"As Planet achieved mission one last year it started to map the entire planet every single day. With this came the need to store tremendous amount of data, being able to serve it using our faboulous Planet Explorer and for you be able to dowload it after you created an account. While getting imagery became critically important , the delivery method lead to questions about platforms for analysis. Mission one further meant that you would be able to analyze time series datasets over weekly and bi weekly periods and understand questions that require dynamic analysis such as vegetation patters, climate variability and changes in hydrological cycles. It generated the single largest trove of high frequency dataset in existence with an unprecedented cadence or repeat over areas. Planet by the numbers from Will Marshall\u2019s post \u00a9 Planet Labs With the need to handle such global-scale and often massive data sets, Google was already building and hosting a platform called Google Earth Engine(GEE) designed to analyze geo-spatial data. Google Earth Engine is a cloud based analysis platform that allows for an indexable and queriable raster and vector environment while including and expanding on raster capabilities. It allows for users to perform large scale analysis on large scale datasets such as Planet's very own. You can read more about the Google Earth Engine platform here These set of tutorials will introduce you to methods in getting imagery onto the Google Earth Engine platform, and how do you quickly visualize and analyze the datasets with the GEE platform. With the multitude of tools and possibilities of building your own analysis tools. The first of it's kind tools will include basic methods such as 4 band operations and can include complex operations in machine learning as the platform evolves. For more information and developer guide on Google Earth Engine you can visit their developer console .","title":"Introduction"},{"location":"projects/Inspecting Satellite Imagery/","text":"Inspecting Satellite Imagery using Rasterio A first look at satellite data with Python At this point, you will have learned different ways of searching for, filtering, and downloading satellite imagery. Now let's use one of these acquired datasets and dig into it a bit with Python. You can get the notebook here Here we're going to use a Python library called rasterio : you may be familiar with it already, or perhaps with the related C library, GDAL . If you've used numpy before, working with rasterio will feel very familiar. import rasterio # feel free to replace example with your own GeoTIFF: # note that this Notebook will assume we re working with PlanetScope 4-band imagery image_file = example.tif satdat = rasterio . open ( image_file ) Basic details What can we learn about this satellite image using just Python? # Get the bounding box of this GeoTIFF satdat . bounds # Get dimensions, in map units (using the example GeoTIFF, that s meters) width = satdat . bounds . right - satdat . bounds . left height = satdat . bounds . top - satdat . bounds . bottom print ( Width: {}, Height: {} . format ( width , height )) # Get dimensions, in pixels px_width = satdat . width px_height = satdat . height print ( Width: {}, Height: {} . format ( px_width , px_height )) # How many meters to a pixel? w = width / px_width h = height / px_height w , h # Get coordinate reference system satdat . crs # Get coordinates of top-left bottom right corners # NOTE: how to do this depends on your Rasterio version -- # if you re running against a pre-1.0 release use satdat.affine instead topleft = satdat . transform * ( 0 , 0 ) botright = satdat . transform * ( width , height ) print ( Top left corner coordinates: {} . format ( topleft )) print ( Bottom right corner coordinates: {} . format ( botright )) # Another way of viewing most of the previous values: # Get the basic metadata of this GeoTIFF satdat . meta Bands So far, we haven't done too much geospatial-raster-specific work yet. Since we know we're inspecting a multispectral satellite image, let's see what we can learn about its bands. # Get the number of bands by listing their indices satdat . indexes Because we know we're look at a PlanetScope 4-band analytic satellite image, we can define the bands by their order: # PlanetScope 4-band band order: BGRN blue = satdat . read ( 1 ) green = satdat . read ( 2 ) red = satdat . read ( 3 ) nir = satdat . read ( 4 ) # or: # blue, green, red, nir = satdat.read() Pixels In a raster dataset, each pixel has a value. Pixels are arranged in a grid, and pixels representing equivalent data have the same value: # bands are stored as numpy arrays print ( type ( blue )) # how many dimensions would a raster have? print ( blue . ndim ) # take a look at the summarized array print ( blue ) # Output a min max pixel value in each band # we ll need to use numpy directly for this import numpy print ( numpy . amin ( blue ), numpy . amax ( blue )) print ( numpy . amin ( green ), numpy . amax ( green )) print ( numpy . amin ( red ), numpy . amax ( red )) print ( numpy . amin ( nir ), numpy . amax ( nir )) # Let s grab the pixel 2km east and 2km south of the upper left corner # get the pixel px_x = satdat . bounds . left + 2000 px_y = satdat . bounds . top - 2000 row , col = satdat . index ( px_x , px_y ) # Now let s look at the value of each band at this pixel print ( Red: {} . format ( red [ row , col ])) print ( Green: {} . format ( green [ row , col ])) print ( Blue: {} . format ( blue [ row , col ])) print ( NIR: {} . format ( nir [ row , col ]))","title":"Inspecting Satellite Imagery"},{"location":"projects/Inspecting Satellite Imagery/#inspecting-satellite-imagery-using-rasterio","text":"","title":"Inspecting Satellite Imagery using Rasterio"},{"location":"projects/Inspecting Satellite Imagery/#a-first-look-at-satellite-data-with-python","text":"At this point, you will have learned different ways of searching for, filtering, and downloading satellite imagery. Now let's use one of these acquired datasets and dig into it a bit with Python. You can get the notebook here Here we're going to use a Python library called rasterio : you may be familiar with it already, or perhaps with the related C library, GDAL . If you've used numpy before, working with rasterio will feel very familiar. import rasterio # feel free to replace example with your own GeoTIFF: # note that this Notebook will assume we re working with PlanetScope 4-band imagery image_file = example.tif satdat = rasterio . open ( image_file )","title":"A first look at satellite data with Python"},{"location":"projects/Inspecting Satellite Imagery/#basic-details","text":"What can we learn about this satellite image using just Python? # Get the bounding box of this GeoTIFF satdat . bounds # Get dimensions, in map units (using the example GeoTIFF, that s meters) width = satdat . bounds . right - satdat . bounds . left height = satdat . bounds . top - satdat . bounds . bottom print ( Width: {}, Height: {} . format ( width , height )) # Get dimensions, in pixels px_width = satdat . width px_height = satdat . height print ( Width: {}, Height: {} . format ( px_width , px_height )) # How many meters to a pixel? w = width / px_width h = height / px_height w , h # Get coordinate reference system satdat . crs # Get coordinates of top-left bottom right corners # NOTE: how to do this depends on your Rasterio version -- # if you re running against a pre-1.0 release use satdat.affine instead topleft = satdat . transform * ( 0 , 0 ) botright = satdat . transform * ( width , height ) print ( Top left corner coordinates: {} . format ( topleft )) print ( Bottom right corner coordinates: {} . format ( botright )) # Another way of viewing most of the previous values: # Get the basic metadata of this GeoTIFF satdat . meta","title":"Basic details"},{"location":"projects/Inspecting Satellite Imagery/#bands","text":"So far, we haven't done too much geospatial-raster-specific work yet. Since we know we're inspecting a multispectral satellite image, let's see what we can learn about its bands. # Get the number of bands by listing their indices satdat . indexes Because we know we're look at a PlanetScope 4-band analytic satellite image, we can define the bands by their order: # PlanetScope 4-band band order: BGRN blue = satdat . read ( 1 ) green = satdat . read ( 2 ) red = satdat . read ( 3 ) nir = satdat . read ( 4 ) # or: # blue, green, red, nir = satdat.read()","title":"Bands"},{"location":"projects/Inspecting Satellite Imagery/#pixels","text":"In a raster dataset, each pixel has a value. Pixels are arranged in a grid, and pixels representing equivalent data have the same value: # bands are stored as numpy arrays print ( type ( blue )) # how many dimensions would a raster have? print ( blue . ndim ) # take a look at the summarized array print ( blue ) # Output a min max pixel value in each band # we ll need to use numpy directly for this import numpy print ( numpy . amin ( blue ), numpy . amax ( blue )) print ( numpy . amin ( green ), numpy . amax ( green )) print ( numpy . amin ( red ), numpy . amax ( red )) print ( numpy . amin ( nir ), numpy . amax ( nir )) # Let s grab the pixel 2km east and 2km south of the upper left corner # get the pixel px_x = satdat . bounds . left + 2000 px_y = satdat . bounds . top - 2000 row , col = satdat . index ( px_x , px_y ) # Now let s look at the value of each band at this pixel print ( Red: {} . format ( red [ row , col ])) print ( Green: {} . format ( green [ row , col ])) print ( Blue: {} . format ( blue [ row , col ])) print ( NIR: {} . format ( nir [ row , col ]))","title":"Pixels"},{"location":"projects/Visualizing Satellite Imagery/","text":"Visualizing Satellite Imagery with Matplotlib Taking a closer look at satellite data with Python In the Inspecting Satellite Imagery Notebook , we learned how to use rasterio to read and manipulate satellite data. There we also learned that, since satellite images are really grids of pixel-values, a satellite image can be interpreted as a multidimensional array of values. You can get the notebook here You may already be familiar with the Python library matplotlib : here, we're going to briefly use that toolset to visually plot satellite data that has been read into a numpy array using rasterio . import rasterio from matplotlib import pyplot as plt # feel free to replace example with your own GeoTIFF: # note that this Notebook will assume we re working with PlanetScope 4-band imagery image_file = example.tif # use rasterio to read in the satellite image satdat = rasterio . open ( image_file ) # load the 4 bands into 2d arrays - recall that we previously learned PlanetScope band order is BGRN b , g , r , n = satdat . read () # use imshow to load the blue band fig = plt . imshow ( b ) # Display the results plt . show () # now let s plot the green band, and add a color map # https://matplotlib.org/users/colormaps.html fig = plt . imshow ( g ) fig . set_cmap ( gist_earth ) # Display the results plt . show () # add a colorbar, and plot the red band fig = plt . imshow ( r ) fig . set_cmap ( inferno ) plt . colorbar () # Display the results plt . show () # finally, we ll plot the NIR band and since axis labels are useless here, let s turn them off fig = plt . imshow ( n ) fig . set_cmap ( winter ) plt . colorbar () plt . axis ( off ) # Display the results plt . show ()","title":"Visualizing Satellite Imagery"},{"location":"projects/Visualizing Satellite Imagery/#visualizing-satellite-imagery-with-matplotlib","text":"","title":"Visualizing Satellite Imagery with Matplotlib"},{"location":"projects/Visualizing Satellite Imagery/#taking-a-closer-look-at-satellite-data-with-python","text":"In the Inspecting Satellite Imagery Notebook , we learned how to use rasterio to read and manipulate satellite data. There we also learned that, since satellite images are really grids of pixel-values, a satellite image can be interpreted as a multidimensional array of values. You can get the notebook here You may already be familiar with the Python library matplotlib : here, we're going to briefly use that toolset to visually plot satellite data that has been read into a numpy array using rasterio . import rasterio from matplotlib import pyplot as plt # feel free to replace example with your own GeoTIFF: # note that this Notebook will assume we re working with PlanetScope 4-band imagery image_file = example.tif # use rasterio to read in the satellite image satdat = rasterio . open ( image_file ) # load the 4 bands into 2d arrays - recall that we previously learned PlanetScope band order is BGRN b , g , r , n = satdat . read () # use imshow to load the blue band fig = plt . imshow ( b ) # Display the results plt . show () # now let s plot the green band, and add a color map # https://matplotlib.org/users/colormaps.html fig = plt . imshow ( g ) fig . set_cmap ( gist_earth ) # Display the results plt . show () # add a colorbar, and plot the red band fig = plt . imshow ( r ) fig . set_cmap ( inferno ) plt . colorbar () # Display the results plt . show () # finally, we ll plot the NIR band and since axis labels are useless here, let s turn them off fig = plt . imshow ( n ) fig . set_cmap ( winter ) plt . colorbar () plt . axis ( off ) # Display the results plt . show ()","title":"Taking a closer look at satellite data with Python"},{"location":"projects/classification/","text":"Image Clasification Guess what we have high resolution imagery at about 70-80 cm Panchromatic and 1m Mulispectral and when Google had acquired Terra Bella(now known as Skysat) they made couple of image collections open source. So you can perform supervised image classification to test out some of the more advanced feature and then match this with field data. The example imagery is over Port of L\u00e1zaro C\u00e1rdenas and the three types of classification namely, random forest, cart and svm type clasifications are performed. You can add the collection using the line below or type Skysat in the Image Catalog var skysat = ee . ImageCollection ( SKYSAT/GEN-A/PUBLIC/ORTHO/MULTISPECTRAL ) You can get link to the overall area code here To get to our specific area //Add the collection var imageCollection = ee . ImageCollection ( SKYSAT/GEN-A/PUBLIC/ORTHO/MULTISPECTRAL ) //Add a point geometry to use as filter print size var geometry = ee . Geometry . Point ([ - 102.17748642229708 , 17.942153910452422 ]) print ( imageCollection . filterBounds ( geometry ). size ()) //Add visualization var vis = { opacity : 1 , bands : [ N , G , R ], min : 132.7061786684951 , max : 3655.0445459691864 , gamma : 1 }; Map . addLayer ( imageCollection . median (), vis , Skysat Median ) Map . setCenter ( - 102.16941833496094 , 17.95048268223829 , 14 ) Map . setOptions ( SATELLITE )","title":"Skysat Image Classification"},{"location":"projects/classification/#image-clasification","text":"Guess what we have high resolution imagery at about 70-80 cm Panchromatic and 1m Mulispectral and when Google had acquired Terra Bella(now known as Skysat) they made couple of image collections open source. So you can perform supervised image classification to test out some of the more advanced feature and then match this with field data. The example imagery is over Port of L\u00e1zaro C\u00e1rdenas and the three types of classification namely, random forest, cart and svm type clasifications are performed. You can add the collection using the line below or type Skysat in the Image Catalog var skysat = ee . ImageCollection ( SKYSAT/GEN-A/PUBLIC/ORTHO/MULTISPECTRAL ) You can get link to the overall area code here To get to our specific area //Add the collection var imageCollection = ee . ImageCollection ( SKYSAT/GEN-A/PUBLIC/ORTHO/MULTISPECTRAL ) //Add a point geometry to use as filter print size var geometry = ee . Geometry . Point ([ - 102.17748642229708 , 17.942153910452422 ]) print ( imageCollection . filterBounds ( geometry ). size ()) //Add visualization var vis = { opacity : 1 , bands : [ N , G , R ], min : 132.7061786684951 , max : 3655.0445459691864 , gamma : 1 }; Map . addLayer ( imageCollection . median (), vis , Skysat Median ) Map . setCenter ( - 102.16941833496094 , 17.95048268223829 , 14 ) Map . setOptions ( SATELLITE )","title":"Image Clasification"},{"location":"projects/downloading-images/","text":"Downloading Images You can download images from Planet using a couple of methods, including but not limited to Planet Explorer or using a client to make requests to the Data API and downloading imagery. Planet Explorer Planet Explorer is probably one of the most useful and beloved interface to interact with and download Planet Labs satellite imagery. Not only does it allow you to filter your images to specific sensors but it also allows you to filter by cloud cover among other things. A neat little trick in Planet Explorer is that once the images are filtered if you want to download multiple images at once in an order you can hold down the control key(if using a windows machine) and click on multiple sets of imagery adding them to the same order. Steps to get satellite imagery from Planet Explorer Once the images have been ordered sit back and relax as the order notification that your delivery is ready to be picked up will be emailed to you. To interact with the Data API and batch download imagery there is host of Planet Platform documentation that teach you how to do that step by step. Batch Download Images Using Planet Python CLI This is the default command line tool that is provided by planet and you can find the project here and it connects to Data API to perform multiple operations such as quick search, activate and download assets among a few other things. Install it easily using pip install planet follow it by planet init to initialize and you are ready to go. A simple setup to download images using a geometry(a simple geometry geojson file) and date range (let us say between 2018-07-01 to 2018-08-31), cloud cover(less than 10% or less than 0.1) could be achieved in a single line of cli command planet data download --item-type PSScene4Band --geom full path to geometry.geojson --date acquired gt 2018-07-01 --date acquired lt 2018-08-31 --range cloud_cover lt 0.1 --asset-type analytic --dest your local directory path Batch Download and Upload to Earth Engine I have also created another stand alone tool apart from the ppipe tool to just download imagery once you have selected area of interest and sensor type. This will work if you have the (Planet Python Client installed). Incase you missed this in housekeeping you can read it again . It is using the Saved search function to allow you to batch download. You can find the tool here . You can pip install it using pip install ppipe This tool is a quick addon to existing application of planet saved searches to download images. This prints all the saved searches that you might have saved using the CLI or using the explorer. In which case you are able to set the filters, choose item types and date ranges and aoi within the Planet Explorer GUI and then be able to use the saved search name to execute a batch download command. This combines activation and download and works only for a single item type that was set in the search. You can choose to provide a limit which limits the number of item-asset combinations to download or use without limit and all items and asset combinations in the aoi will be downloaded. Using with limits python saved_search_download.py search_name analytic C:\\planet_demo 10 Without limits the setup becomes python saved_search_download.py search_name analytic C:\\planet_demo I added the functionality to use Planet's own async downlaoder to download based on a geometry A setup using geojson needs to include other filters too and a typical setup would be ppipe dasync --infile C:\\Users\\johndoe\\geometry.geojson --item PSScene4Band --asset analytic --local C:\\planet --start 2018-06-01 --end 2018-08-01 --cmin 0 --cmax 0.4 Using a stuctured json file that you might have created earlier means you don't have to pass additional filters everytime python ppipe.py dasync --infile C:\\Users\\johndoe\\geometry.json --item PSScene4Band --asset analytic_xml --local C:\\planet_demo However, you can still decide to pass the filters and the filters you pass will overwrite existing filters python ppipe.py dasync --infile C:\\Users\\johndoe\\geometry.json --item PSScene4Band --asset analytic_xml --local C:\\planet_demo --start 2018-06-01 --end 2018-08-01 --cmin 0 --cmax 0.4","title":"Downloading Images"},{"location":"projects/downloading-images/#downloading-images","text":"You can download images from Planet using a couple of methods, including but not limited to Planet Explorer or using a client to make requests to the Data API and downloading imagery.","title":"Downloading Images"},{"location":"projects/downloading-images/#planet-explorer","text":"Planet Explorer is probably one of the most useful and beloved interface to interact with and download Planet Labs satellite imagery. Not only does it allow you to filter your images to specific sensors but it also allows you to filter by cloud cover among other things. A neat little trick in Planet Explorer is that once the images are filtered if you want to download multiple images at once in an order you can hold down the control key(if using a windows machine) and click on multiple sets of imagery adding them to the same order. Steps to get satellite imagery from Planet Explorer Once the images have been ordered sit back and relax as the order notification that your delivery is ready to be picked up will be emailed to you. To interact with the Data API and batch download imagery there is host of Planet Platform documentation that teach you how to do that step by step.","title":"Planet Explorer"},{"location":"projects/downloading-images/#batch-download-images","text":"","title":"Batch Download Images"},{"location":"projects/downloading-images/#using-planet-python-cli","text":"This is the default command line tool that is provided by planet and you can find the project here and it connects to Data API to perform multiple operations such as quick search, activate and download assets among a few other things. Install it easily using pip install planet follow it by planet init to initialize and you are ready to go. A simple setup to download images using a geometry(a simple geometry geojson file) and date range (let us say between 2018-07-01 to 2018-08-31), cloud cover(less than 10% or less than 0.1) could be achieved in a single line of cli command planet data download --item-type PSScene4Band --geom full path to geometry.geojson --date acquired gt 2018-07-01 --date acquired lt 2018-08-31 --range cloud_cover lt 0.1 --asset-type analytic --dest your local directory path","title":"Using Planet Python CLI"},{"location":"projects/downloading-images/#batch-download-and-upload-to-earth-engine","text":"I have also created another stand alone tool apart from the ppipe tool to just download imagery once you have selected area of interest and sensor type. This will work if you have the (Planet Python Client installed). Incase you missed this in housekeeping you can read it again . It is using the Saved search function to allow you to batch download. You can find the tool here . You can pip install it using pip install ppipe This tool is a quick addon to existing application of planet saved searches to download images. This prints all the saved searches that you might have saved using the CLI or using the explorer. In which case you are able to set the filters, choose item types and date ranges and aoi within the Planet Explorer GUI and then be able to use the saved search name to execute a batch download command. This combines activation and download and works only for a single item type that was set in the search. You can choose to provide a limit which limits the number of item-asset combinations to download or use without limit and all items and asset combinations in the aoi will be downloaded. Using with limits python saved_search_download.py search_name analytic C:\\planet_demo 10 Without limits the setup becomes python saved_search_download.py search_name analytic C:\\planet_demo I added the functionality to use Planet's own async downlaoder to download based on a geometry A setup using geojson needs to include other filters too and a typical setup would be ppipe dasync --infile C:\\Users\\johndoe\\geometry.geojson --item PSScene4Band --asset analytic --local C:\\planet --start 2018-06-01 --end 2018-08-01 --cmin 0 --cmax 0.4 Using a stuctured json file that you might have created earlier means you don't have to pass additional filters everytime python ppipe.py dasync --infile C:\\Users\\johndoe\\geometry.json --item PSScene4Band --asset analytic_xml --local C:\\planet_demo However, you can still decide to pass the filters and the filters you pass will overwrite existing filters python ppipe.py dasync --infile C:\\Users\\johndoe\\geometry.json --item PSScene4Band --asset analytic_xml --local C:\\planet_demo --start 2018-06-01 --end 2018-08-01 --cmin 0 --cmax 0.4","title":"Batch Download and Upload to Earth Engine"},{"location":"projects/edges/","text":"Edge Detection You can also run powerful functions such as edge detection using Hough and Canny transforms for example for single images as well as on collections to do edge counts, connectivity measures among a few other applications. Similar to earlier example you can access the full script here or copy and past the same code into code.earthengine.google.com //Add an AOI var aoi = ee . FeatureCollection ( users/io-work-1/vector/subset ) //Zoom to AOI Map . centerObject ( aoi , 15 ) //Add image and visualization var image = ee . Image ( users/io-work-1/open-ca/PS4BSR/20180621_182201_1008_3B_AnalyticMS_SR ) var vis = { opacity : 1 , bands : [ b4 , b3 , b2 ], min :- 433.8386769876429 , max : 2822.7077530529555 , gamma : 1 }; var ndvi = image . normalizedDifference ([ b4 , b3 ]); // Apply a Canny edge detector. var canny = ee . Algorithms . CannyEdgeDetector ({ image : ndvi , threshold : 0.2 }). multiply ( 255 ); // Apply the Hough transform. var h = ee . Algorithms . HoughTransform ({ image : canny , gridSize : 256 , inputThreshold : 80 , lineThreshold : 80 }); // Display. Map . addLayer ( image , vis , source_image ); Map . addLayer ( ndvi ,{ min : - 0.05 , max : 0.5 }, NDVI , false ) Map . addLayer ( canny . updateMask ( canny ), { min : 0 , max : 1 , palette : blue }, canny ); Map . addLayer ( h . updateMask ( h ), { min : 0 , max : 1 , palette : red }, hough ); Map . setOptions ( SATELLITE )","title":"Edge Detection"},{"location":"projects/edges/#edge-detection","text":"You can also run powerful functions such as edge detection using Hough and Canny transforms for example for single images as well as on collections to do edge counts, connectivity measures among a few other applications. Similar to earlier example you can access the full script here or copy and past the same code into code.earthengine.google.com //Add an AOI var aoi = ee . FeatureCollection ( users/io-work-1/vector/subset ) //Zoom to AOI Map . centerObject ( aoi , 15 ) //Add image and visualization var image = ee . Image ( users/io-work-1/open-ca/PS4BSR/20180621_182201_1008_3B_AnalyticMS_SR ) var vis = { opacity : 1 , bands : [ b4 , b3 , b2 ], min :- 433.8386769876429 , max : 2822.7077530529555 , gamma : 1 }; var ndvi = image . normalizedDifference ([ b4 , b3 ]); // Apply a Canny edge detector. var canny = ee . Algorithms . CannyEdgeDetector ({ image : ndvi , threshold : 0.2 }). multiply ( 255 ); // Apply the Hough transform. var h = ee . Algorithms . HoughTransform ({ image : canny , gridSize : 256 , inputThreshold : 80 , lineThreshold : 80 }); // Display. Map . addLayer ( image , vis , source_image ); Map . addLayer ( ndvi ,{ min : - 0.05 , max : 0.5 }, NDVI , false ) Map . addLayer ( canny . updateMask ( canny ), { min : 0 , max : 1 , palette : blue }, canny ); Map . addLayer ( h . updateMask ( h ), { min : 0 , max : 1 , palette : red }, hough ); Map . setOptions ( SATELLITE )","title":"Edge Detection"},{"location":"projects/explore/","text":"PlanetScope Explorer and Exporter I decided to add this last minute because this is such a simple implementation of existing examples in Google Earth Engine and makes like easy for you to export things to your Google Drive. In theory you can modify this to export to your Google Cloud Service Bucket instead of drive and so on. The Code is a bit long so you can access is directly here .","title":"PlanetScope Explorer & Exporter"},{"location":"projects/explore/#planetscope-explorer-and-exporter","text":"I decided to add this last minute because this is such a simple implementation of existing examples in Google Earth Engine and makes like easy for you to export things to your Google Drive. In theory you can modify this to export to your Google Cloud Service Bucket instead of drive and so on. The Code is a bit long so you can access is directly here .","title":"PlanetScope Explorer and Exporter"},{"location":"projects/export/","text":"Export Images in Earth Engine When we are all said and done we still want to export the images. Google Earth Engine allows you to export images externally into two subsystems, a Google Cloud Storage Bucket(Free quota upto 5 GB) or Google Drive (This is tied to your overall quota). The method we are exploring right now is export to Google Drive, and then being able to import the analyzed image into any local tool or libraries. It is possible to export entire collections to drive using batch exports in the python API client. This avoids the need for you to click on the Run button everytime an export task has to be started. Export Window: Export Image to Google Drive For this setup we look at how we added PlanetScope Surface Reflectance data earlier , filtering it using date and using Cloud cover for the scene. The next step we are building an function to calculate monthly composites from Jan till end of June 2018. Note that this is another way of creating a function where we have inserted the map function and the collection inside the function so it can be run directly. We might be interested in sorting these collections using month and hence we set the month as a metadata for each image in the cloud free composite. The last step that is added is the Export to drive function, where we set up the image name, the image type, the scale and the region refers to areas over which we are exporting this imagery. You can access the entire code here or copy and paste from below //Add an AOI var aoi = ee . FeatureCollection ( users/io-work-1/vector/subset ) //Zoom to AOI Map . centerObject ( aoi , 15 ) //Add an image collection var collection = ee . ImageCollection ( users/io-work-1/open-ca/PS4BSR ) //print collection properties print ( Collection , collection ) //Create Monthly Composite from PlanetScope Surface Reflectance var months = ee . List . sequence ( 6 , 8 ) var multimonth = ee . ImageCollection ( months . map ( function ( m ) { var start = ee . Date . fromYMD ( 2018 , m , 1 ) var end = start . advance ( 1 , month ); var image = collection . filterDate ( start , end ). median (); return image . set ( month , m ) })) print ( multimonth ); //Add a visualization var vis = { opacity : 1 , bands : [ b4 , b3 , b2 ], min :- 433.8386769876429 , max : 2822.7077530529555 , gamma : 1 }; //Add the Image Map . addLayer ( ee . Image ( ee . ImageCollection ( multimonth ). first ()). clip ( aoi ), vis , ee . String ( 2018- ). cat ( ee . String ( ee . Image ( ee . ImageCollection ( multimonth ). first ()). get ( month ))). slice ( 0 , 6 ). getInfo ()) //Export Imagery Export . image . toDrive ({ image : ee . Image ( ee . ImageCollection ( multimonth ). first ()) . select ([ b1 , b2 , b3 , b4 ]). toUint16 (), description : Median-Image-Export , folder : SatSummit-Test , scale : 3 , region : aoi , maxPixels : 10 e12 }) Exporting video seems like the obvious thing to do after this. For this a couple of things to keep in mind, you can only export 3 band videos cast to a 8 bit image per frame. You can sort these images before export and that is the ordering of the frames. Complete link with export can be found here or add to existing code //Add an AOI var aoi = ee . FeatureCollection ( users/io-work-1/vector/subset ) //Zoom to AOI Map . centerObject ( aoi , 15 ) //Add an image collection var collection = ee . ImageCollection ( users/io-work-1/open-ca/PS4BSR ) //print collection properties print ( Collection , collection ) //Create Monthly Composite from PlanetScope Surface Reflectance var months = ee . List . sequence ( 6 , 8 ) var multimonth = ee . ImageCollection ( months . map ( function ( m ) { var start = ee . Date . fromYMD ( 2018 , m , 1 ) var end = start . advance ( 1 , month ); var image = collection . filterDate ( start , end ). median (); return image . set ( month , m ) })) print ( multimonth ); //Add a visualization var vis = { opacity : 1 , bands : [ b4 , b3 , b2 ], min :- 433.8386769876429 , max : 2822.7077530529555 , gamma : 1 }; //Add the Image Map . addLayer ( ee . Image ( ee . ImageCollection ( multimonth ). first ()). clip ( aoi ), vis , ee . String ( 2018- ). cat ( ee . String ( ee . Image ( ee . ImageCollection ( multimonth ). first ()). get ( month ))). slice ( 0 , 6 ). getInfo ()) //Export Imagery Export . image . toDrive ({ image : ee . Image ( ee . ImageCollection ( multimonth ). first ()) . select ([ b1 , b2 , b3 , b4 ]). toUint16 (), description : Median-Image-Export , folder : EE-Terra-Test , scale : 3 , region : aoi , maxPixels : 10 e12 }) // Load and format the collection to export. var frame = ee . ImageCollection ( multimonth ) . sort ( year ) . select ([ b4 , b3 , b2 ]) . map ( function ( image ) { return image . visualize ({ bands : [ b4 , b3 , b2 ], min :- 433.8386769876429 , max : 2822.7077530529555 }) . set ( month , image . get ( month )); }); // Export video Export . video . toDrive ({ collection : frame , folder : SatSummit-Test , description : SatSummit-Video , dimensions : 1080 , framesPerSecond : 1 , region : aoi });","title":"Earth Engine exports"},{"location":"projects/export/#export-images-in-earth-engine","text":"When we are all said and done we still want to export the images. Google Earth Engine allows you to export images externally into two subsystems, a Google Cloud Storage Bucket(Free quota upto 5 GB) or Google Drive (This is tied to your overall quota). The method we are exploring right now is export to Google Drive, and then being able to import the analyzed image into any local tool or libraries. It is possible to export entire collections to drive using batch exports in the python API client. This avoids the need for you to click on the Run button everytime an export task has to be started. Export Window: Export Image to Google Drive For this setup we look at how we added PlanetScope Surface Reflectance data earlier , filtering it using date and using Cloud cover for the scene. The next step we are building an function to calculate monthly composites from Jan till end of June 2018. Note that this is another way of creating a function where we have inserted the map function and the collection inside the function so it can be run directly. We might be interested in sorting these collections using month and hence we set the month as a metadata for each image in the cloud free composite. The last step that is added is the Export to drive function, where we set up the image name, the image type, the scale and the region refers to areas over which we are exporting this imagery. You can access the entire code here or copy and paste from below //Add an AOI var aoi = ee . FeatureCollection ( users/io-work-1/vector/subset ) //Zoom to AOI Map . centerObject ( aoi , 15 ) //Add an image collection var collection = ee . ImageCollection ( users/io-work-1/open-ca/PS4BSR ) //print collection properties print ( Collection , collection ) //Create Monthly Composite from PlanetScope Surface Reflectance var months = ee . List . sequence ( 6 , 8 ) var multimonth = ee . ImageCollection ( months . map ( function ( m ) { var start = ee . Date . fromYMD ( 2018 , m , 1 ) var end = start . advance ( 1 , month ); var image = collection . filterDate ( start , end ). median (); return image . set ( month , m ) })) print ( multimonth ); //Add a visualization var vis = { opacity : 1 , bands : [ b4 , b3 , b2 ], min :- 433.8386769876429 , max : 2822.7077530529555 , gamma : 1 }; //Add the Image Map . addLayer ( ee . Image ( ee . ImageCollection ( multimonth ). first ()). clip ( aoi ), vis , ee . String ( 2018- ). cat ( ee . String ( ee . Image ( ee . ImageCollection ( multimonth ). first ()). get ( month ))). slice ( 0 , 6 ). getInfo ()) //Export Imagery Export . image . toDrive ({ image : ee . Image ( ee . ImageCollection ( multimonth ). first ()) . select ([ b1 , b2 , b3 , b4 ]). toUint16 (), description : Median-Image-Export , folder : SatSummit-Test , scale : 3 , region : aoi , maxPixels : 10 e12 }) Exporting video seems like the obvious thing to do after this. For this a couple of things to keep in mind, you can only export 3 band videos cast to a 8 bit image per frame. You can sort these images before export and that is the ordering of the frames. Complete link with export can be found here or add to existing code //Add an AOI var aoi = ee . FeatureCollection ( users/io-work-1/vector/subset ) //Zoom to AOI Map . centerObject ( aoi , 15 ) //Add an image collection var collection = ee . ImageCollection ( users/io-work-1/open-ca/PS4BSR ) //print collection properties print ( Collection , collection ) //Create Monthly Composite from PlanetScope Surface Reflectance var months = ee . List . sequence ( 6 , 8 ) var multimonth = ee . ImageCollection ( months . map ( function ( m ) { var start = ee . Date . fromYMD ( 2018 , m , 1 ) var end = start . advance ( 1 , month ); var image = collection . filterDate ( start , end ). median (); return image . set ( month , m ) })) print ( multimonth ); //Add a visualization var vis = { opacity : 1 , bands : [ b4 , b3 , b2 ], min :- 433.8386769876429 , max : 2822.7077530529555 , gamma : 1 }; //Add the Image Map . addLayer ( ee . Image ( ee . ImageCollection ( multimonth ). first ()). clip ( aoi ), vis , ee . String ( 2018- ). cat ( ee . String ( ee . Image ( ee . ImageCollection ( multimonth ). first ()). get ( month ))). slice ( 0 , 6 ). getInfo ()) //Export Imagery Export . image . toDrive ({ image : ee . Image ( ee . ImageCollection ( multimonth ). first ()) . select ([ b1 , b2 , b3 , b4 ]). toUint16 (), description : Median-Image-Export , folder : EE-Terra-Test , scale : 3 , region : aoi , maxPixels : 10 e12 }) // Load and format the collection to export. var frame = ee . ImageCollection ( multimonth ) . sort ( year ) . select ([ b4 , b3 , b2 ]) . map ( function ( image ) { return image . visualize ({ bands : [ b4 , b3 , b2 ], min :- 433.8386769876429 , max : 2822.7077530529555 }) . set ( month , image . get ( month )); }); // Export video Export . video . toDrive ({ collection : frame , folder : SatSummit-Test , description : SatSummit-Video , dimensions : 1080 , framesPerSecond : 1 , region : aoi });","title":"Export Images in Earth Engine"},{"location":"projects/functions/","text":"Functions in Earth Engine: NDVI While single image operations are direct and can be applied to the imagery for a one to one result. Applying any kind of analysis on a single image means you have to call the image and run the analysis which is quick and easy. To be able to turn this same into a function that you can iterate over an entire collection requires us to convert a single analysis to a function. A function is then mapped or run over an entire collection. To avoid any errors make sure that the collection images are consistent and have same name and number of band and characteristics. For this setup we look at how we added PlanetScope Surface Reflectance data earlier , filtering it using date and further using Cloud cover for the scene. The next step we are building an function to calculate Normalized Difference Vegetation Index (NDVI) over the entire collection which takes an image collection and iteratively passes an image to the function. The resultant structure is also an image collection where we are returning a single band which is the NDVI. Note that we also renamed the band to NDVI since they are not autorenamed You can access the script here or copy and paste from below //Add an AOI var aoi = ee . FeatureCollection ( users/io-work-1/vector/subset ) //Zoom to the AOI Map . centerObject ( aoi , 13 ) //Add an image collection var collection = ee . ImageCollection ( users/io-work-1/open-ca/PS4BSR ) //Filtering an Image Collection var filtered = collection . filterDate ( 2018-06-01 , 2018-08-31 ) //Filter for March . filterMetadata ( cloud_cover , less_than , 0.2 ) //Cloud cover less than 20% . filterBounds ( aoi ) //Filter by only the subset area of interest //print filtered collection properties print ( Filtered Collection , filtered ) /*==================================================*/ //Writing a function var addNDVI = function ( image ) { var ndvi = image . normalizedDifference ([ b4 , b3 ]). rename ( NDVI ); return ndvi ; }; var ndvicoll = filtered . map ( addNDVI ) print ( NDVI Collection , ndvicoll ) //Let s add a palette for us to show the results var ndvivis = { opacity : 1 , bands : [ NDVI ], min :- 0.259 , max : 0.57 , palette : [ d49e8a , ffcfb4 , ecffcf , 94ff8d , 3eff56 , 15cc23 ]}; //Add the median of the result Map . addLayer ( ee . Image ( ndvicoll . median ()). clip ( aoi ), ndvivis , NDVI )","title":"Functions"},{"location":"projects/functions/#functions-in-earth-engine-ndvi","text":"While single image operations are direct and can be applied to the imagery for a one to one result. Applying any kind of analysis on a single image means you have to call the image and run the analysis which is quick and easy. To be able to turn this same into a function that you can iterate over an entire collection requires us to convert a single analysis to a function. A function is then mapped or run over an entire collection. To avoid any errors make sure that the collection images are consistent and have same name and number of band and characteristics. For this setup we look at how we added PlanetScope Surface Reflectance data earlier , filtering it using date and further using Cloud cover for the scene. The next step we are building an function to calculate Normalized Difference Vegetation Index (NDVI) over the entire collection which takes an image collection and iteratively passes an image to the function. The resultant structure is also an image collection where we are returning a single band which is the NDVI. Note that we also renamed the band to NDVI since they are not autorenamed You can access the script here or copy and paste from below //Add an AOI var aoi = ee . FeatureCollection ( users/io-work-1/vector/subset ) //Zoom to the AOI Map . centerObject ( aoi , 13 ) //Add an image collection var collection = ee . ImageCollection ( users/io-work-1/open-ca/PS4BSR ) //Filtering an Image Collection var filtered = collection . filterDate ( 2018-06-01 , 2018-08-31 ) //Filter for March . filterMetadata ( cloud_cover , less_than , 0.2 ) //Cloud cover less than 20% . filterBounds ( aoi ) //Filter by only the subset area of interest //print filtered collection properties print ( Filtered Collection , filtered ) /*==================================================*/ //Writing a function var addNDVI = function ( image ) { var ndvi = image . normalizedDifference ([ b4 , b3 ]). rename ( NDVI ); return ndvi ; }; var ndvicoll = filtered . map ( addNDVI ) print ( NDVI Collection , ndvicoll ) //Let s add a palette for us to show the results var ndvivis = { opacity : 1 , bands : [ NDVI ], min :- 0.259 , max : 0.57 , palette : [ d49e8a , ffcfb4 , ecffcf , 94ff8d , 3eff56 , 15cc23 ]}; //Add the median of the result Map . addLayer ( ee . Image ( ndvicoll . median ()). clip ( aoi ), ndvivis , NDVI )","title":"Functions in Earth Engine: NDVI"},{"location":"projects/getting-images-ee/","text":"Getting Images into Google Earth Engine For the simplest users getting images into GEE begins with the Image upload tool located inside GEE. Once you have added the filename you can edit additional metadata such as start time, cloud cover information if you have that from the metadata file among other things. This tool does not have a way for you to ingest any metadata automatically so it has to be fed manually. The image name is automatically filled in with the filename that you select when uploading. Note you cannot select more than one image and upload as a single image if they overlap each other. To handle which we have the concept of image collections. Where you can upload many images. To import images into collections, you have to either import them manually as images first and then copy them into the collection one by one or for now use an external tool to help. For now you can use the tool I made to batch upload collections along with their metadata into Google Earth Engine. You can read about the tool, it's setup and it's operation at this Planet Story Incase you have a Google Cloud Storage bucket you can also push images automatically to be ingested into GEE. Though this requires interaction with gsutil and starting ingestion function for each image. The GEE guide for image ingestion can be found here","title":"Getting Images into Google Earth Engine"},{"location":"projects/getting-images-ee/#getting-images-into-google-earth-engine","text":"For the simplest users getting images into GEE begins with the Image upload tool located inside GEE. Once you have added the filename you can edit additional metadata such as start time, cloud cover information if you have that from the metadata file among other things. This tool does not have a way for you to ingest any metadata automatically so it has to be fed manually. The image name is automatically filled in with the filename that you select when uploading. Note you cannot select more than one image and upload as a single image if they overlap each other. To handle which we have the concept of image collections. Where you can upload many images. To import images into collections, you have to either import them manually as images first and then copy them into the collection one by one or for now use an external tool to help. For now you can use the tool I made to batch upload collections along with their metadata into Google Earth Engine. You can read about the tool, it's setup and it's operation at this Planet Story Incase you have a Google Cloud Storage bucket you can also push images automatically to be ingested into GEE. Though this requires interaction with gsutil and starting ingestion function for each image. The GEE guide for image ingestion can be found here","title":"Getting Images into Google Earth Engine"},{"location":"projects/housekeeping/","text":"Housekeeping and Setup For most users data usage often boils down to the software you use to analyze and manipulate images and how you are going to work with them. So here are going to do some housekeeping and setup depending on which tools and setup you are most comfortable with 1) Python Setup and libraries Depending on what type of usage you are interested and the libraries you want to use you can find Python installations here . And here are some of the libraries you can use with that including but not limited to GDAL, Scipy , Numpy , Matplotlib , Pandas , Fiona and Shapely . This list is not exhaustive and include anything else you might need like scikit or learn opencv All of Pypi is your oyster for most systems you can copy and paste this if you have pip on your native command line or terminal pip install numpy scipy fiona shapely matplotlib pandas For Ubuntu and Debian users this might work better and I borrowed it from the installation page at Scipy sudo apt-get install python-numpy python-scipy python-matplotlib python-pandas Note that GDAL involves a few additional steps for installation on windows machines You can read more about it here Two other tools or setups which might be handy include virtualenv virtualenv allows the user to create and manage seperate package installations fo multiple projects. Think of this as your new project can have its own set of user libraries seperated from the native python libraries. It allows you to create isolated environments for projects and install packages into that virtual isolated environments. A simple installation would be pip install virtualenv You can get more details about installation on different operation systems and activation of this environment by reading their docs . jupyter notebook The jupyter hub defined jupyter notebook as The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. A lot of the tool chains and processes have been already built into jupyter notebooks for you to use, 2) Planet and Google Earth Engine(GEE) Command Line Interface(CLI) Setup You planet account comes with a brand new CLI and it allows you to perfrom basic functions such as search for ID[s] and for images in a specific location, export all image footprint in your area of interest and so on. Installation is pretty simple pip install planet You installation steps from earlier means you have managed to not only create the Google Earth Engine account but also installed its client. Incase you have missed it go to their main reference page for installation of their python client. Since you can consume Earth Engine using both Javascript(in browser) and Python(locally). 3) Location to GEE datasets For the purpose of this workshop, I have downloaded and ingested Planet imagery into three distinct colllections (PlanetScope 4 Band analytic, Planet 4 analytic surface analytic, RapidEye OrthoTile) If the data is maintained as open access license, you can add any of the datasets by simply adding the following lines. For now you access these here var planetscope4b_toar = ee . ImageCollection ( users/io-work-1/open-ca/PS4BTOAR ) var planetscope4b_sr = ee . ImageCollection ( users/io-work-1/open-ca/PS4BSR ) //get size of collection print ( PlanetScope TOAR Size , planetscope4b . size ()) print ( PlanetScope SR , planetscope4b_sr . size ()) //Get the first element from each collection print ( PTOAR Image , planetscope4b_toar . first ()) print ( PSR Image , planetscope4b_sr . first ()) for those using python API you can still access a collection import ee ee . Initialize () planetscope = ee . ImageCollection ( users/io-work-1/open-ca/PS4BTOAR ) ##you can even check how many images does the collection have print ( planetscope . size () . getInfo ()) 4) Adding additional Images For a minute there imagine you want to work with more data apart from the few areas we talked about, the Education and Research account gives you 10,000 square kilometer and you can then upload it into GEE. For the simplest users getting images into GEE begins with the Image upload tool located inside GEE. Once you have added the filename you can edit additional metadata such as start time, cloud cover information if you have that from the metadata file among other things. This tool does not have a way for you to ingest any metadata automatically so it has to be fed manually. The image name is automatically filled in with the filename that you select when uploading. Note you cannot select more than one image and upload as a single image if they overlap each other. To handle which we have the concept of image collections. Where you can upload many images. To import images into collections, you have to either import them manually as images first and then copy them into the collection one by one or for now use an external tool to help such as using the Google Earth Engine CLI. For now you can use the tool I made to batch upload collections along with their metadata into Google Earth Engine . You can install this by simply typing pip install ppipe You can read about the tool, it's setup and it's operation at this Planet Story Incase you have a Google Cloud Storage bucket you can also push images automatically to be ingested into GEE. Though this requires interaction with gsutil and starting ingestion function for each image. The GEE guide for image ingestion can be found here 5) Additional Tools and Toolboxes for Local Analysis If you need to handle the data locally using Matlab, QGIS or ArcMap make sure you have these softwares installed. The images can then be downloaded and analyzed using multiple methods and toolsets. A lot of these softwares have additional capabilities to help you further use Planet data. You can find a better reference of external integration here ENVI Integration ESRI Integration Cesium Integration Boundless PCI Geomatics","title":"Basic Housekeeping and Setup"},{"location":"projects/housekeeping/#housekeeping-and-setup","text":"For most users data usage often boils down to the software you use to analyze and manipulate images and how you are going to work with them. So here are going to do some housekeeping and setup depending on which tools and setup you are most comfortable with","title":"Housekeeping and Setup"},{"location":"projects/housekeeping/#1-python-setup-and-libraries","text":"Depending on what type of usage you are interested and the libraries you want to use you can find Python installations here . And here are some of the libraries you can use with that including but not limited to GDAL, Scipy , Numpy , Matplotlib , Pandas , Fiona and Shapely . This list is not exhaustive and include anything else you might need like scikit or learn opencv All of Pypi is your oyster for most systems you can copy and paste this if you have pip on your native command line or terminal pip install numpy scipy fiona shapely matplotlib pandas For Ubuntu and Debian users this might work better and I borrowed it from the installation page at Scipy sudo apt-get install python-numpy python-scipy python-matplotlib python-pandas Note that GDAL involves a few additional steps for installation on windows machines You can read more about it here Two other tools or setups which might be handy include","title":"1) Python Setup and libraries"},{"location":"projects/housekeeping/#virtualenv","text":"virtualenv allows the user to create and manage seperate package installations fo multiple projects. Think of this as your new project can have its own set of user libraries seperated from the native python libraries. It allows you to create isolated environments for projects and install packages into that virtual isolated environments. A simple installation would be pip install virtualenv You can get more details about installation on different operation systems and activation of this environment by reading their docs .","title":"virtualenv"},{"location":"projects/housekeeping/#jupyter-notebook","text":"The jupyter hub defined jupyter notebook as The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. A lot of the tool chains and processes have been already built into jupyter notebooks for you to use,","title":"jupyter notebook"},{"location":"projects/housekeeping/#2-planet-and-google-earth-enginegee-command-line-interfacecli-setup","text":"You planet account comes with a brand new CLI and it allows you to perfrom basic functions such as search for ID[s] and for images in a specific location, export all image footprint in your area of interest and so on. Installation is pretty simple pip install planet You installation steps from earlier means you have managed to not only create the Google Earth Engine account but also installed its client. Incase you have missed it go to their main reference page for installation of their python client. Since you can consume Earth Engine using both Javascript(in browser) and Python(locally).","title":"2) Planet and Google Earth Engine(GEE) Command Line Interface(CLI) Setup"},{"location":"projects/housekeeping/#3-location-to-gee-datasets","text":"For the purpose of this workshop, I have downloaded and ingested Planet imagery into three distinct colllections (PlanetScope 4 Band analytic, Planet 4 analytic surface analytic, RapidEye OrthoTile) If the data is maintained as open access license, you can add any of the datasets by simply adding the following lines. For now you access these here var planetscope4b_toar = ee . ImageCollection ( users/io-work-1/open-ca/PS4BTOAR ) var planetscope4b_sr = ee . ImageCollection ( users/io-work-1/open-ca/PS4BSR ) //get size of collection print ( PlanetScope TOAR Size , planetscope4b . size ()) print ( PlanetScope SR , planetscope4b_sr . size ()) //Get the first element from each collection print ( PTOAR Image , planetscope4b_toar . first ()) print ( PSR Image , planetscope4b_sr . first ()) for those using python API you can still access a collection import ee ee . Initialize () planetscope = ee . ImageCollection ( users/io-work-1/open-ca/PS4BTOAR ) ##you can even check how many images does the collection have print ( planetscope . size () . getInfo ())","title":"3) Location to GEE datasets"},{"location":"projects/housekeeping/#4-adding-additional-images","text":"For a minute there imagine you want to work with more data apart from the few areas we talked about, the Education and Research account gives you 10,000 square kilometer and you can then upload it into GEE. For the simplest users getting images into GEE begins with the Image upload tool located inside GEE. Once you have added the filename you can edit additional metadata such as start time, cloud cover information if you have that from the metadata file among other things. This tool does not have a way for you to ingest any metadata automatically so it has to be fed manually. The image name is automatically filled in with the filename that you select when uploading. Note you cannot select more than one image and upload as a single image if they overlap each other. To handle which we have the concept of image collections. Where you can upload many images. To import images into collections, you have to either import them manually as images first and then copy them into the collection one by one or for now use an external tool to help such as using the Google Earth Engine CLI. For now you can use the tool I made to batch upload collections along with their metadata into Google Earth Engine . You can install this by simply typing pip install ppipe You can read about the tool, it's setup and it's operation at this Planet Story Incase you have a Google Cloud Storage bucket you can also push images automatically to be ingested into GEE. Though this requires interaction with gsutil and starting ingestion function for each image. The GEE guide for image ingestion can be found here","title":"4) Adding additional Images"},{"location":"projects/housekeeping/#5-additional-tools-and-toolboxes-for-local-analysis","text":"If you need to handle the data locally using Matlab, QGIS or ArcMap make sure you have these softwares installed. The images can then be downloaded and analyzed using multiple methods and toolsets. A lot of these softwares have additional capabilities to help you further use Planet data. You can find a better reference of external integration here ENVI Integration ESRI Integration Cesium Integration Boundless PCI Geomatics","title":"5) Additional Tools and Toolboxes for Local Analysis"},{"location":"projects/imagecollection/","text":"Image Collections in Earth Engine While single images are great to do quick analytics, the true power of the Earth Engine environment comes with the possibility of looking at really large and heavy image collections and to be able to push analysis towards the data, rather than the need for the data to travel at all. In the GEE environment image collections have their own characteristic setup and are composted with single images that we discussed earlier. They can often have the same or different band structure but generally share a similar metadata structure for filtering and querying. Large scale image collections such as Landsat and Sentinel image collections are ingested on the fly and are actively maintained till there imagery and processing pipelines feeds are maintained byt he agencies supplying the imagery. Images as well as image collections can be moved into GEE environment to allow you to use both your data and the GEE catalog data within the same platform. For those who are concerned with access to datasets, this means that though Earth Engine allows an easier way to share datasets across users, private folder, collections and imagery are private and are not here the section from their Terms and Conditions page Intellectual Property Rights. Except as expressly set forth in this Agreement, this Agreement does not grant either party any rights, implied or otherwise, to the other\u2019s content or any of the other\u2019s intellectual property. As between the parties, Customer owns all Intellectual Property Rights in Customer Data, Customer Code, and Application(s), and Google owns all Intellectual Property Rights in the Services and Software. These image collection as well as individual imaegs again have defined data type,scales and projections along with some default properties such as an index and ID among other system properties. So we can query these properties, print them and add them var filtered = ee . ImageCollection ( users/io-work-1/open-ca/PS4BSR ) . filterDate ( 2018-06-01 , 2018-07-30 ) //Filter for March print ( Date Filter Only , filtered . size ()) var filtered = ee . ImageCollection ( users/io-work-1/open-ca/PS4BSR ) . filterDate ( 2018-06-01 , 2018-07-30 ) //Filter for March . filterMetadata ( cloud_cover , less_than , 0.01 ) //Cloud cover less than 1% print ( Multi Filter , filtered . size ()) To have a look at all of the raster catalog you can find them listed here or you can try the list I update every week","title":"Image Collection"},{"location":"projects/imagecollection/#image-collections-in-earth-engine","text":"While single images are great to do quick analytics, the true power of the Earth Engine environment comes with the possibility of looking at really large and heavy image collections and to be able to push analysis towards the data, rather than the need for the data to travel at all. In the GEE environment image collections have their own characteristic setup and are composted with single images that we discussed earlier. They can often have the same or different band structure but generally share a similar metadata structure for filtering and querying. Large scale image collections such as Landsat and Sentinel image collections are ingested on the fly and are actively maintained till there imagery and processing pipelines feeds are maintained byt he agencies supplying the imagery. Images as well as image collections can be moved into GEE environment to allow you to use both your data and the GEE catalog data within the same platform. For those who are concerned with access to datasets, this means that though Earth Engine allows an easier way to share datasets across users, private folder, collections and imagery are private and are not here the section from their Terms and Conditions page Intellectual Property Rights. Except as expressly set forth in this Agreement, this Agreement does not grant either party any rights, implied or otherwise, to the other\u2019s content or any of the other\u2019s intellectual property. As between the parties, Customer owns all Intellectual Property Rights in Customer Data, Customer Code, and Application(s), and Google owns all Intellectual Property Rights in the Services and Software. These image collection as well as individual imaegs again have defined data type,scales and projections along with some default properties such as an index and ID among other system properties. So we can query these properties, print them and add them var filtered = ee . ImageCollection ( users/io-work-1/open-ca/PS4BSR ) . filterDate ( 2018-06-01 , 2018-07-30 ) //Filter for March print ( Date Filter Only , filtered . size ()) var filtered = ee . ImageCollection ( users/io-work-1/open-ca/PS4BSR ) . filterDate ( 2018-06-01 , 2018-07-30 ) //Filter for March . filterMetadata ( cloud_cover , less_than , 0.01 ) //Cloud cover less than 1% print ( Multi Filter , filtered . size ()) To have a look at all of the raster catalog you can find them listed here or you can try the list I update every week","title":"Image Collections in Earth Engine"},{"location":"projects/images/","text":"Images in Earth Engine In the GEE environment images are stored in Cloud Optimized Geospatial tiles instead of a single image which allows for running an analysis this scale. This means that though the input imagery comes in know formats such as geotiff , MrSid and img these datasets post ingestion into GEE are converted into tiles that are used for at scale analysis. All images that are ingested into either GEE(s) Raster Catalog or your own personal folder and stored in folder or collections of images as you would expect to see when doing deep time stack analysis. These images have defined data type,scales and projections along with some default properties such as an index and ID among other system properties. So we can query these properties, print them and add them //Setting up a Geometry var geometry = ee . FeatureCollection ( users/io-work-1/vector/openca ) //PlanetScope is 4 band imagery, we are adding surface reflectance image with visualization var vis = { opacity : 1 , bands : [ b4 , b3 , b2 ], min : 208 , max : 2385 , gamma : 1 }; //Add an image var image = ee . Image ( users/io-work-1/open-ca/PS4BSR/20180621_182201_1008_3B_AnalyticMS_SR ) print ( Single Image , image ) //Center the Map to the image and add the image Map . centerObject ( geometry , 12 ) Map . addLayer ( image , vis , Image ) //Clip an image var clipped = image . clip ( geometry ) Map . addLayer ( clipped , vis , Clipped Image ) //Change BaseMap to Satellite Map . setOptions ( SATELLITE )","title":"Images"},{"location":"projects/images/#images-in-earth-engine","text":"In the GEE environment images are stored in Cloud Optimized Geospatial tiles instead of a single image which allows for running an analysis this scale. This means that though the input imagery comes in know formats such as geotiff , MrSid and img these datasets post ingestion into GEE are converted into tiles that are used for at scale analysis. All images that are ingested into either GEE(s) Raster Catalog or your own personal folder and stored in folder or collections of images as you would expect to see when doing deep time stack analysis. These images have defined data type,scales and projections along with some default properties such as an index and ID among other system properties. So we can query these properties, print them and add them //Setting up a Geometry var geometry = ee . FeatureCollection ( users/io-work-1/vector/openca ) //PlanetScope is 4 band imagery, we are adding surface reflectance image with visualization var vis = { opacity : 1 , bands : [ b4 , b3 , b2 ], min : 208 , max : 2385 , gamma : 1 }; //Add an image var image = ee . Image ( users/io-work-1/open-ca/PS4BSR/20180621_182201_1008_3B_AnalyticMS_SR ) print ( Single Image , image ) //Center the Map to the image and add the image Map . centerObject ( geometry , 12 ) Map . addLayer ( image , vis , Image ) //Clip an image var clipped = image . clip ( geometry ) Map . addLayer ( clipped , vis , Clipped Image ) //Change BaseMap to Satellite Map . setOptions ( SATELLITE )","title":"Images in Earth Engine"},{"location":"projects/landsat-ps-comparison/","text":"Comparing Landsat and PlanetScope Scenes A common and powerful workflow for analysis is comparing or combining information from multiple sources. This tutorial demonstrates comparing a set of Landsat and PlanetScope scenes. In this tutorial, and the notebook we download scenes from the two sensors taken on the same day at the same place, visualize them, resample the Landsat scene to match the pixel resolution and locations of the PlanetScope scene, and perform pixel-by-pixel comparison of their near-infrared (NIR) bands. Our comparison of the NIR bands is identification of the difference between the scaled NIR bands. We find that most differences between the NIR bands are at high-resolution features and are due to the lower resolution of the Landsat scene. However, we also find a few fields show noticeable difference in the NIR bands. We theorize that these differences may be due to the different spectral responses of the two sensors and the fields containing different crop types than the surrounding fields. These results suggest that an analysis utilizing both Landsat8 and PlanetScope scenes may be able to better differentiate crop types than just using one sensor. Ideas for extending beyond this notebook: 1. Mask the scenes using the PlanetScope Unusable Data Mask and Landsat Quality Assurance bands 2. Convert the PlanetScope scene to reflectance and then do not normalize the bands in the difference calculation Install Dependencies and Set up Notebook import os import shutil from subprocess import check_output , STDOUT , CalledProcessError import urllib.request import numpy as np import rasterio import requests % matplotlib inline Download Scenes In the crossovers notebook , we identified many Landsat/PlanetScope crossovers within the same day that occured between January and August 2017. From that list, we are going to download the following set of scenes: - PSOrthoTile 644787_1056721_2017-07-25_0f52 - Landsat8L1G LC80430332017206LGN00 PSOrthoTile Landsat8L1G These scenes represent a crossover between Landsat8 and PlanetScope on July 25, 2017. For the Landsat8L1G scene, we download band 5, which is the NIR band ( ref ). To download the scenes, we use the planet CLI because it handles activating, waiting for activation, and downloading the file. We will save the scenes in the data folder. This folder isn't tracked by git so the downloaded image file will not bloat our git repository. Download PlanetScope Orthotile Scene # create the data folder if it doesn t exist data_folder = data if not os . path . isdir ( data_folder ): os . mkdir ( data_folder ) # first test if scene file exists, if not, use planet cli to download image # note that this assumes a bash shell, available in unix-based operating systems ! test - f data / 644787 _1056721_2017 - 07 - 25 _0f52_BGRN_Analytic . tif || \\ planet data download -- item - type PSOrthoTile \\ -- asset - type analytic \\ -- string - in id 644787 _1056721_2017 - 07 - 25 _0f52 \\ -- dest data # store the image filename for processing and make sure the file exists pl_filename = os . path . join ( data , 644787_1056721_2017-07-25_0f52_BGRN_Analytic.tif ) print ( pl_filename ) assert os . path . isfile ( pl_filename ) /data/644787_1056721_2017-07-25_0f52_BGRN_Analytic.tif Download Landsat NIR Band Landsat is distributed with each asset as an individual band. Band 5 is the NIR band. Since we only plan on using the NIR band, we will download just that asset. NOTE: The command below should work, but currently there is a bug in the planet CLI. Until that is fixed, use the curl command to download the asset from the endpoint directly. # !planet data download --item-type Landsat8L1G \\ # --asset-type analytic_b5 \\ # --string-in id LC80430332017206LGN00 \\ # --dest data # !ls -l --block-size=M data # The long way of downloading an asset. Doesn t use the planet CLI def get_auth (): auth = ( os . environ [ PL_API_KEY ], ) return auth def get_asset_info ( asset ): auth = get_auth () item_assets_url = https://api.planet.com/data/v1/item-types/Landsat8L1G/items/LC80430332017206LGN00/assets/ r = requests . get ( item_assets_url , auth = auth ) assert r . status_code == 200 assets_resp = r . json () return assets_resp [ asset ] def activate ( asset ): asset_info = get_asset_info ( asset ) activation_link = asset_info [ _links ][ activate ] auth = get_auth () r = requests . post ( activation_link , auth = auth ) assert r . status_code == 204 def download ( asset , path ): if not os . path . isfile ( path ): asset_info = get_asset_info ( asset ) download_link = asset_info [ location ] urllib . request . urlretrieve ( download_link , path ) asset = analytic_b5 activate ( asset ) # it may take a while for the asset to be activated. If this fails, wait a while and rerun landsat_filename = os . path . join ( data , LC80430332017206LGN00_{}.tif . format ( asset )) download ( asset , landsat_filename ) # store the Landsat band filename for processing and make sure the file exists l8_nir_orig_filename = os . path . join ( data , LC80430332017206LGN00_analytic_b5.tif ) print ( l8_nir_orig_filename ) assert os . path . isfile ( l8_nir_orig_filename ) /data/LC80430332017206LGN00_analytic_b5.tif Warp Landsat Scene to Planet Scene For pixel-by-pixel comparison of the Landsat and Planet scenes, the two scenes must have the same extents, the pixels must be the same size, and the pixels must exactly overlap each other. This can all be achieved by warping one scene to the other scene. We warp the Landsat scene to the Planet scene because the Planet scene is much higher resolution than the Landsat scene and we want to use the highest resolution possible for our comparison. The GDAL command-line interface, specifically gdalwarp , is the easiest way to warp one image to another image. def prepare_l8_band ( band_filename , dst_filename , out_filename ): Project, crop, and resample landsat 8 band to match dst_filename image. # we use cubic method for interpolation because band represents continuous data method = cubic with rasterio . open ( band_filename , r ) as src : with rasterio . open ( dst_filename , r ) as dst : # crop crop_options = _gdalwarp_crop_options ( dst . bounds , dst . crs ) # resample width , height = dst . shape resample_options = _gdalwarp_resample_options ( str ( width ), str ( height ), method ) options = crop_options + resample_options # run gdalwarp _gdalwarp ( band_filename , out_filename , options ) def _gdalwarp_crop_options ( bounds , crs ): xmin , ymin , xmax , ymax = [ str ( b ) for b in bounds ] return [ -te , xmin , ymin , xmax , ymax ] def _gdalwarp_resample_options ( width , height , technique ): # for technique options, see: http://www.gdal.org/gdalwarp.html return [ -ts , width , height , -r , technique ] def _gdalwarp ( input_filename , output_filename , options ): commands = _gdalwarp_commands ( input_filename , output_filename , options ) # print error if one is encountered # https://stackoverflow.com/questions/29580663/save-error-message-of-subprocess-command try : output = check_output ( commands , stderr = STDOUT ) except CalledProcessError as exc : print ( exc . output ) def _gdalwarp_commands ( input_filename , output_filename , options ): commands = [ gdalwarp ] + options + \\ [ -overwrite , input_filename , output_filename ] print ( . join ( commands )) return commands l8_nir_filename = os . path . join ( data , LC80430332017206LGN00_analytic_b5_warped.tif ) prepare_l8_band ( l8_nir_orig_filename , pl_filename , l8_nir_filename ) gdalwarp -te 643500.0 4223500.0 668500.0 4248500.0 -ts 8000 8000 -r cubic -overwrite data/LC80430332017206LGN00_analytic_b5.tif data/LC80430332017206LGN00_analytic_b5_warped.tif Load and Visualize NIR Bands Before moving on to comparing the NIR bands, we load the NIR bands from each scene and visualize the bands. Instead of including a huge chunk of code for visualizing the NIR band, we put that code in a local script ( visual.py ) and import here. Ideally, we would use the PlanetScope Unusable Data Mask (UDM) and Landsat Quality Assurance (QA) bands to create the pixel masks. In the interest of keeping this tutorial focused, we perform a simple and brute-force masking where we mask pixels that are equal to the blackfill NoData value, 0. import visual def load_l8_nir (): with rasterio . open ( l8_nir_filename , r ) as src : nir_band = src . read ()[ 0 ] # mask wherever the pixel value is the NoData value, 0 mask = nir_band == 0 return np . ma . array ( nir_band , mask = mask ) l8_nir_band = load_l8_nir () visual . plot_image ([ l8_nir_band ], title = Landsat8 NIR ) def load_pl_nir (): with rasterio . open ( pl_filename , r ) as src : band_num = 3 nir_band = src . read ()[ band_num ] mask = nir_band == 0 # mask = src.read_masks()[band_num] == 0 return np . ma . array ( nir_band , mask = mask ) pl_nir_band = load_pl_nir () visual . plot_image ([ pl_nir_band ], title = PSOrthotile NIR ) Compare NIR Bands In this section we look at the difference in response between the NIR bands of the two sensors. The difference is calculated as the absolute value of the subtraction of one normalized NIR band from the other normalized NIR band. Note: Landsat8 is corrected to reflectance and PlanetScope is corrected to radiance. The conversion between reflectance and radiance is achieved by scaling the entire band. In this comparison, we normalize the two NIR bands to 0-1 anyway, so the radiance/reflectance difference doesn't affect us. def normalize ( ndarray , old_min = None , old_max = None , new_min = 0 , new_max = 1 ): old_min = old_min if old_min is not None else ndarray . min () old_max = old_max if old_max is not None else ndarray . max () # https://en.wikipedia.org/wiki/Normalization_(image_processing) return ( ndarray . astype ( np . float ) - old_min ) * ( new_max - new_min ) / ( old_max - old_min ) + new_min # Scale the bands so that the maximum value is 1 diff_band = abs ( normalize ( l8_nir_band , old_min = 0 ) - normalize ( pl_nir_band , old_min = 0 )) # if a pixel is masked in either of the NIR bands, mask it in the difference band diff_band . mask = np . any ([ l8_nir_band . mask , pl_nir_band . mask ], axis = 0 ) visual . plot_image ([ diff_band ]) In general, the major differences between the NIR bands occur at high-resolution features (edges of fields, roads, and populated areas) and are caused by the lower resolution of the Landsat8 sensor. However, there are a few larger regions, which appear to be fields, that show some difference between the NIR bands. Lets zoom into one such region, the square field located just right of center of the image. region = ( np . s_ [ 3000 : 5000 ], np . s_ [ 3500 : 5500 ]) # create a (rows, columns) numpy slice for indexing the array figsize = ( 5 , 5 ) visual . plot_image ([ diff_band [ region ]], title = NIR Difference , figsize = figsize ) visual . plot_image ([ pl_nir_band [ region ]], title = PlanetScope NIR , figsize = figsize ) visual . plot_image ([ l8_nir_band [ region ]], title = Landsat8 NIR , figsize = figsize ) Interestingly, it appears the square field which pops out in the difference image is less differentiated from the surrounding fields in the Landsat scene than in the PlanetScope scene. Since both scenes were collected on the same day, this is likely due to a different in the spectral responses of the NIR bands for the two sensors combined with the crop type of that field. The center wavelength of the NIR response for the PlanetScope sensor is 825nm, while it is 865nm for the Landsat sensor . This shows that an analysis utilizing both Landsat8 and PlanetScope scenes may be able to better differentiate crop types. There is great potential in combining scenes from multiple sensors for analysis.","title":"Landsat Planet Comparisons"},{"location":"projects/landsat-ps-comparison/#comparing-landsat-and-planetscope-scenes","text":"A common and powerful workflow for analysis is comparing or combining information from multiple sources. This tutorial demonstrates comparing a set of Landsat and PlanetScope scenes. In this tutorial, and the notebook we download scenes from the two sensors taken on the same day at the same place, visualize them, resample the Landsat scene to match the pixel resolution and locations of the PlanetScope scene, and perform pixel-by-pixel comparison of their near-infrared (NIR) bands. Our comparison of the NIR bands is identification of the difference between the scaled NIR bands. We find that most differences between the NIR bands are at high-resolution features and are due to the lower resolution of the Landsat scene. However, we also find a few fields show noticeable difference in the NIR bands. We theorize that these differences may be due to the different spectral responses of the two sensors and the fields containing different crop types than the surrounding fields. These results suggest that an analysis utilizing both Landsat8 and PlanetScope scenes may be able to better differentiate crop types than just using one sensor. Ideas for extending beyond this notebook: 1. Mask the scenes using the PlanetScope Unusable Data Mask and Landsat Quality Assurance bands 2. Convert the PlanetScope scene to reflectance and then do not normalize the bands in the difference calculation","title":"Comparing Landsat and PlanetScope Scenes"},{"location":"projects/landsat-ps-comparison/#install-dependencies-and-set-up-notebook","text":"import os import shutil from subprocess import check_output , STDOUT , CalledProcessError import urllib.request import numpy as np import rasterio import requests % matplotlib inline","title":"Install Dependencies and Set up Notebook"},{"location":"projects/landsat-ps-comparison/#download-scenes","text":"In the crossovers notebook , we identified many Landsat/PlanetScope crossovers within the same day that occured between January and August 2017. From that list, we are going to download the following set of scenes: - PSOrthoTile 644787_1056721_2017-07-25_0f52 - Landsat8L1G LC80430332017206LGN00 PSOrthoTile Landsat8L1G These scenes represent a crossover between Landsat8 and PlanetScope on July 25, 2017. For the Landsat8L1G scene, we download band 5, which is the NIR band ( ref ). To download the scenes, we use the planet CLI because it handles activating, waiting for activation, and downloading the file. We will save the scenes in the data folder. This folder isn't tracked by git so the downloaded image file will not bloat our git repository.","title":"Download Scenes"},{"location":"projects/landsat-ps-comparison/#download-planetscope-orthotile-scene","text":"# create the data folder if it doesn t exist data_folder = data if not os . path . isdir ( data_folder ): os . mkdir ( data_folder ) # first test if scene file exists, if not, use planet cli to download image # note that this assumes a bash shell, available in unix-based operating systems ! test - f data / 644787 _1056721_2017 - 07 - 25 _0f52_BGRN_Analytic . tif || \\ planet data download -- item - type PSOrthoTile \\ -- asset - type analytic \\ -- string - in id 644787 _1056721_2017 - 07 - 25 _0f52 \\ -- dest data # store the image filename for processing and make sure the file exists pl_filename = os . path . join ( data , 644787_1056721_2017-07-25_0f52_BGRN_Analytic.tif ) print ( pl_filename ) assert os . path . isfile ( pl_filename ) /data/644787_1056721_2017-07-25_0f52_BGRN_Analytic.tif","title":"Download PlanetScope Orthotile Scene"},{"location":"projects/landsat-ps-comparison/#download-landsat-nir-band","text":"Landsat is distributed with each asset as an individual band. Band 5 is the NIR band. Since we only plan on using the NIR band, we will download just that asset. NOTE: The command below should work, but currently there is a bug in the planet CLI. Until that is fixed, use the curl command to download the asset from the endpoint directly. # !planet data download --item-type Landsat8L1G \\ # --asset-type analytic_b5 \\ # --string-in id LC80430332017206LGN00 \\ # --dest data # !ls -l --block-size=M data # The long way of downloading an asset. Doesn t use the planet CLI def get_auth (): auth = ( os . environ [ PL_API_KEY ], ) return auth def get_asset_info ( asset ): auth = get_auth () item_assets_url = https://api.planet.com/data/v1/item-types/Landsat8L1G/items/LC80430332017206LGN00/assets/ r = requests . get ( item_assets_url , auth = auth ) assert r . status_code == 200 assets_resp = r . json () return assets_resp [ asset ] def activate ( asset ): asset_info = get_asset_info ( asset ) activation_link = asset_info [ _links ][ activate ] auth = get_auth () r = requests . post ( activation_link , auth = auth ) assert r . status_code == 204 def download ( asset , path ): if not os . path . isfile ( path ): asset_info = get_asset_info ( asset ) download_link = asset_info [ location ] urllib . request . urlretrieve ( download_link , path ) asset = analytic_b5 activate ( asset ) # it may take a while for the asset to be activated. If this fails, wait a while and rerun landsat_filename = os . path . join ( data , LC80430332017206LGN00_{}.tif . format ( asset )) download ( asset , landsat_filename ) # store the Landsat band filename for processing and make sure the file exists l8_nir_orig_filename = os . path . join ( data , LC80430332017206LGN00_analytic_b5.tif ) print ( l8_nir_orig_filename ) assert os . path . isfile ( l8_nir_orig_filename ) /data/LC80430332017206LGN00_analytic_b5.tif","title":"Download Landsat NIR Band"},{"location":"projects/landsat-ps-comparison/#warp-landsat-scene-to-planet-scene","text":"For pixel-by-pixel comparison of the Landsat and Planet scenes, the two scenes must have the same extents, the pixels must be the same size, and the pixels must exactly overlap each other. This can all be achieved by warping one scene to the other scene. We warp the Landsat scene to the Planet scene because the Planet scene is much higher resolution than the Landsat scene and we want to use the highest resolution possible for our comparison. The GDAL command-line interface, specifically gdalwarp , is the easiest way to warp one image to another image. def prepare_l8_band ( band_filename , dst_filename , out_filename ): Project, crop, and resample landsat 8 band to match dst_filename image. # we use cubic method for interpolation because band represents continuous data method = cubic with rasterio . open ( band_filename , r ) as src : with rasterio . open ( dst_filename , r ) as dst : # crop crop_options = _gdalwarp_crop_options ( dst . bounds , dst . crs ) # resample width , height = dst . shape resample_options = _gdalwarp_resample_options ( str ( width ), str ( height ), method ) options = crop_options + resample_options # run gdalwarp _gdalwarp ( band_filename , out_filename , options ) def _gdalwarp_crop_options ( bounds , crs ): xmin , ymin , xmax , ymax = [ str ( b ) for b in bounds ] return [ -te , xmin , ymin , xmax , ymax ] def _gdalwarp_resample_options ( width , height , technique ): # for technique options, see: http://www.gdal.org/gdalwarp.html return [ -ts , width , height , -r , technique ] def _gdalwarp ( input_filename , output_filename , options ): commands = _gdalwarp_commands ( input_filename , output_filename , options ) # print error if one is encountered # https://stackoverflow.com/questions/29580663/save-error-message-of-subprocess-command try : output = check_output ( commands , stderr = STDOUT ) except CalledProcessError as exc : print ( exc . output ) def _gdalwarp_commands ( input_filename , output_filename , options ): commands = [ gdalwarp ] + options + \\ [ -overwrite , input_filename , output_filename ] print ( . join ( commands )) return commands l8_nir_filename = os . path . join ( data , LC80430332017206LGN00_analytic_b5_warped.tif ) prepare_l8_band ( l8_nir_orig_filename , pl_filename , l8_nir_filename ) gdalwarp -te 643500.0 4223500.0 668500.0 4248500.0 -ts 8000 8000 -r cubic -overwrite data/LC80430332017206LGN00_analytic_b5.tif data/LC80430332017206LGN00_analytic_b5_warped.tif","title":"Warp Landsat Scene to Planet Scene"},{"location":"projects/landsat-ps-comparison/#load-and-visualize-nir-bands","text":"Before moving on to comparing the NIR bands, we load the NIR bands from each scene and visualize the bands. Instead of including a huge chunk of code for visualizing the NIR band, we put that code in a local script ( visual.py ) and import here. Ideally, we would use the PlanetScope Unusable Data Mask (UDM) and Landsat Quality Assurance (QA) bands to create the pixel masks. In the interest of keeping this tutorial focused, we perform a simple and brute-force masking where we mask pixels that are equal to the blackfill NoData value, 0. import visual def load_l8_nir (): with rasterio . open ( l8_nir_filename , r ) as src : nir_band = src . read ()[ 0 ] # mask wherever the pixel value is the NoData value, 0 mask = nir_band == 0 return np . ma . array ( nir_band , mask = mask ) l8_nir_band = load_l8_nir () visual . plot_image ([ l8_nir_band ], title = Landsat8 NIR ) def load_pl_nir (): with rasterio . open ( pl_filename , r ) as src : band_num = 3 nir_band = src . read ()[ band_num ] mask = nir_band == 0 # mask = src.read_masks()[band_num] == 0 return np . ma . array ( nir_band , mask = mask ) pl_nir_band = load_pl_nir () visual . plot_image ([ pl_nir_band ], title = PSOrthotile NIR )","title":"Load and Visualize NIR Bands"},{"location":"projects/landsat-ps-comparison/#compare-nir-bands","text":"In this section we look at the difference in response between the NIR bands of the two sensors. The difference is calculated as the absolute value of the subtraction of one normalized NIR band from the other normalized NIR band. Note: Landsat8 is corrected to reflectance and PlanetScope is corrected to radiance. The conversion between reflectance and radiance is achieved by scaling the entire band. In this comparison, we normalize the two NIR bands to 0-1 anyway, so the radiance/reflectance difference doesn't affect us. def normalize ( ndarray , old_min = None , old_max = None , new_min = 0 , new_max = 1 ): old_min = old_min if old_min is not None else ndarray . min () old_max = old_max if old_max is not None else ndarray . max () # https://en.wikipedia.org/wiki/Normalization_(image_processing) return ( ndarray . astype ( np . float ) - old_min ) * ( new_max - new_min ) / ( old_max - old_min ) + new_min # Scale the bands so that the maximum value is 1 diff_band = abs ( normalize ( l8_nir_band , old_min = 0 ) - normalize ( pl_nir_band , old_min = 0 )) # if a pixel is masked in either of the NIR bands, mask it in the difference band diff_band . mask = np . any ([ l8_nir_band . mask , pl_nir_band . mask ], axis = 0 ) visual . plot_image ([ diff_band ]) In general, the major differences between the NIR bands occur at high-resolution features (edges of fields, roads, and populated areas) and are caused by the lower resolution of the Landsat8 sensor. However, there are a few larger regions, which appear to be fields, that show some difference between the NIR bands. Lets zoom into one such region, the square field located just right of center of the image. region = ( np . s_ [ 3000 : 5000 ], np . s_ [ 3500 : 5500 ]) # create a (rows, columns) numpy slice for indexing the array figsize = ( 5 , 5 ) visual . plot_image ([ diff_band [ region ]], title = NIR Difference , figsize = figsize ) visual . plot_image ([ pl_nir_band [ region ]], title = PlanetScope NIR , figsize = figsize ) visual . plot_image ([ l8_nir_band [ region ]], title = Landsat8 NIR , figsize = figsize ) Interestingly, it appears the square field which pops out in the difference image is less differentiated from the surrounding fields in the Landsat scene than in the PlanetScope scene. Since both scenes were collected on the same day, this is likely due to a different in the spectral responses of the NIR bands for the two sensors combined with the crop type of that field. The center wavelength of the NIR response for the PlanetScope sensor is 825nm, while it is 865nm for the Landsat sensor . This shows that an analysis utilizing both Landsat8 and PlanetScope scenes may be able to better differentiate crop types. There is great potential in combining scenes from multiple sensors for analysis.","title":"Compare NIR Bands"},{"location":"projects/multimonth/","text":"Monthly Cloud Free Composites in Earth Engine One of the most sought after functions in Earth Engine is the possibility of using deep time stack imagery to create cloud free composites. One of the simplest way of thinking about this is to use reducers that we talked about earlier, where we look at an entire stack of pixels and choose the median value of the distribution of pixel across stack and we end up getting a cloud free composite over the given time period. Depending on the number of images, the actual number of cloud free images in the overall stack your results may need more fine tune adjustments. Multi Month Composite: A single month is added FCC For this setup we look at how we added PlanetScope Surface Reflectance data earlier , filtering it using date and Cloud cover for the scene. The next step we are building an function to calculate monthly composites from June to August 2018. Note that this is another way of creating a function where we have inserted the map function and the collection inside the function so it can be run directly. We might be interested in sorting these collections using month and hence we set the month as a metadata for each image in the cloud free composite. You can get the complete code here or copy and paste it from below //Add an AOI var aoi = ee . FeatureCollection ( users/io-work-1/vector/subset ) //Zoom to AOI Map . centerObject ( aoi , 15 ) //Add an image collection var collection = ee . ImageCollection ( users/io-work-1/open-ca/PS4BSR ) //print collection properties print ( Collection , collection ) //Create Monthly Composite from PlanetScope Surface Reflectance var months = ee . List . sequence ( 6 , 8 ) var multimonth = ee . ImageCollection ( months . map ( function ( m ) { var start = ee . Date . fromYMD ( 2018 , m , 1 ) var end = start . advance ( 1 , month ); var image = collection . filterDate ( start , end ). median (); return image . set ( month , m ) })) print ( multimonth ); //Add a visualization var vis = { opacity : 1 , bands : [ b4 , b3 , b2 ], min :- 433.8386769876429 , max : 2822.7077530529555 , gamma : 1 }; //Add the Image Map . addLayer ( ee . Image ( ee . ImageCollection ( multimonth ). first ()). clip ( aoi ), vis , ee . String ( 2018- ). cat ( ee . String ( ee . Image ( ee . ImageCollection ( multimonth ). first ()). get ( month ))). slice ( 0 , 6 ). getInfo ())","title":"Monthly Cloud free composites"},{"location":"projects/multimonth/#monthly-cloud-free-composites-in-earth-engine","text":"One of the most sought after functions in Earth Engine is the possibility of using deep time stack imagery to create cloud free composites. One of the simplest way of thinking about this is to use reducers that we talked about earlier, where we look at an entire stack of pixels and choose the median value of the distribution of pixel across stack and we end up getting a cloud free composite over the given time period. Depending on the number of images, the actual number of cloud free images in the overall stack your results may need more fine tune adjustments. Multi Month Composite: A single month is added FCC For this setup we look at how we added PlanetScope Surface Reflectance data earlier , filtering it using date and Cloud cover for the scene. The next step we are building an function to calculate monthly composites from June to August 2018. Note that this is another way of creating a function where we have inserted the map function and the collection inside the function so it can be run directly. We might be interested in sorting these collections using month and hence we set the month as a metadata for each image in the cloud free composite. You can get the complete code here or copy and paste it from below //Add an AOI var aoi = ee . FeatureCollection ( users/io-work-1/vector/subset ) //Zoom to AOI Map . centerObject ( aoi , 15 ) //Add an image collection var collection = ee . ImageCollection ( users/io-work-1/open-ca/PS4BSR ) //print collection properties print ( Collection , collection ) //Create Monthly Composite from PlanetScope Surface Reflectance var months = ee . List . sequence ( 6 , 8 ) var multimonth = ee . ImageCollection ( months . map ( function ( m ) { var start = ee . Date . fromYMD ( 2018 , m , 1 ) var end = start . advance ( 1 , month ); var image = collection . filterDate ( start , end ). median (); return image . set ( month , m ) })) print ( multimonth ); //Add a visualization var vis = { opacity : 1 , bands : [ b4 , b3 , b2 ], min :- 433.8386769876429 , max : 2822.7077530529555 , gamma : 1 }; //Add the Image Map . addLayer ( ee . Image ( ee . ImageCollection ( multimonth ). first ()). clip ( aoi ), vis , ee . String ( 2018- ). cat ( ee . String ( ee . Image ( ee . ImageCollection ( multimonth ). first ()). get ( month ))). slice ( 0 , 6 ). getInfo ())","title":"Monthly Cloud Free Composites in Earth Engine"},{"location":"projects/reducers/","text":"Reducers Charts in Earth Engine While single image operations are direct and can be applied to the imagery for a one to one result. Applying any kind of analysis on a single image means you have to call the image and run the analysis which is quick and easy. To be able to turn this same into a function that you can iterate over an entire collection requires us to convert a single analysis to a function. A function is then mapped or run over an entire collection. To avoid any errors make sure that the collection images are consistent and have same name and number of band and characteristics. Source: Image Collection Reductions from Google Earth Engine For this setup we look at how we added PlanetScope Surface Reflectance data earlier , filtering it using date and Cloud cover for the scene. The next step we are building an function to calculate Normalized Difference Vegetation Index (NDVI) over the entire collection which takes an image collection and iteratively passes an image to the function. The resultant structure is also an image collection where we are returning a single band which is the NDVI. Note that we also renamed the band to NDVI since they are not autorenamed. Now the additional step we added here was running the produced collection through a median reducer. We can then print the median values. You can access the code here or copy and paste from below //Add an AOI var aoi = ee . FeatureCollection ( users/io-work-1/vector/subset ) //Zoom to AOI Map . centerObject ( aoi , 14 ) //Add an image collection var collection = ee . ImageCollection ( users/io-work-1/open-ca/PS4BSR ) //Filtering an Image Collection var filtered = collection . filterDate ( 2018-06-01 , 2018-08-31 ) //Filter for March . filterMetadata ( cloud_cover , less_than , 0.1 ) //Cloud cover less than 20% . filterBounds ( aoi ) //Filter by only the subset area of interest //print filtered collection properties print ( Filtered Collection , filtered ) /*==================================================*/ //Writing a function var addNDVI = function ( image ) { var ndvi = image . normalizedDifference ([ b4 , b3 ]). rename ( NDVI ); return ndvi ; }; var ndvicoll = filtered . map ( addNDVI ) print ( NDVI Collection , ndvicoll ) //Let s add a palette for us to show the results var ndvivis = { opacity : 1 , bands : [ NDVI ], min :- 0.259 , max : 0.57 , palette : [ d49e8a , ffcfb4 , ecffcf , 94ff8d , 3eff56 , 15cc23 ]}; //Add the median of the result Map . addLayer ( ee . Image ( ndvicoll . median ()). clip ( aoi ), ndvivis , NDVI ) //Add an reducer var ndviav = ndvicoll . reduce ( ee . Reducer . max ()); Map . addLayer ( ndviav . select ( NDVI_max ). rename ( NDVI ). clip ( aoi ), ndvivis , NDVI Max ) print ( ndviav ) Map . setOptions ( SATELLITE )","title":"Reducers and Charts"},{"location":"projects/reducers/#reducers-charts-in-earth-engine","text":"While single image operations are direct and can be applied to the imagery for a one to one result. Applying any kind of analysis on a single image means you have to call the image and run the analysis which is quick and easy. To be able to turn this same into a function that you can iterate over an entire collection requires us to convert a single analysis to a function. A function is then mapped or run over an entire collection. To avoid any errors make sure that the collection images are consistent and have same name and number of band and characteristics. Source: Image Collection Reductions from Google Earth Engine For this setup we look at how we added PlanetScope Surface Reflectance data earlier , filtering it using date and Cloud cover for the scene. The next step we are building an function to calculate Normalized Difference Vegetation Index (NDVI) over the entire collection which takes an image collection and iteratively passes an image to the function. The resultant structure is also an image collection where we are returning a single band which is the NDVI. Note that we also renamed the band to NDVI since they are not autorenamed. Now the additional step we added here was running the produced collection through a median reducer. We can then print the median values. You can access the code here or copy and paste from below //Add an AOI var aoi = ee . FeatureCollection ( users/io-work-1/vector/subset ) //Zoom to AOI Map . centerObject ( aoi , 14 ) //Add an image collection var collection = ee . ImageCollection ( users/io-work-1/open-ca/PS4BSR ) //Filtering an Image Collection var filtered = collection . filterDate ( 2018-06-01 , 2018-08-31 ) //Filter for March . filterMetadata ( cloud_cover , less_than , 0.1 ) //Cloud cover less than 20% . filterBounds ( aoi ) //Filter by only the subset area of interest //print filtered collection properties print ( Filtered Collection , filtered ) /*==================================================*/ //Writing a function var addNDVI = function ( image ) { var ndvi = image . normalizedDifference ([ b4 , b3 ]). rename ( NDVI ); return ndvi ; }; var ndvicoll = filtered . map ( addNDVI ) print ( NDVI Collection , ndvicoll ) //Let s add a palette for us to show the results var ndvivis = { opacity : 1 , bands : [ NDVI ], min :- 0.259 , max : 0.57 , palette : [ d49e8a , ffcfb4 , ecffcf , 94ff8d , 3eff56 , 15cc23 ]}; //Add the median of the result Map . addLayer ( ee . Image ( ndvicoll . median ()). clip ( aoi ), ndvivis , NDVI ) //Add an reducer var ndviav = ndvicoll . reduce ( ee . Reducer . max ()); Map . addLayer ( ndviav . select ( NDVI_max ). rename ( NDVI ). clip ( aoi ), ndvivis , NDVI Max ) print ( ndviav ) Map . setOptions ( SATELLITE )","title":"Reducers &amp; Charts in Earth Engine"},{"location":"projects/rpl/","text":"Registering for a Planet account What you need first to get started in simply to register for a Planet account. These account will almost immediately gain access to the Open California Dataset which is maintained regulary and is perhaps one of the largest open imagery dataset at this spatial and temporal resolution. You can find more information about the Open California project here . These datasets and full-resolution imagery for the entire state of California are covered under a CC BY-SA 4.0 license via Planet's Open California initiative. If you are a university researchers, academics, and/or scientists, your free account allows you to download 10,000 square kilometers of data for non commercial use, every month, anywhere in the world. You can apply for Education and Research account here Sign up for a Planet Account Planet Explorer is a powerful tool for exploring Planet's catalog of daily imagery and worldwide mosaics directly in your browser. It's also your gateway to creating a Planet Account,and gaining access to Planet's APIs.To sign up, visit planet.com/explorer and click Get Started : Get started with Planet Explorer From there, click Sign Up in the top right of your screen, and enter your email address to receive an invitation: Sign up with Planet Explorer Check your email follow the directions to complete the registration process. Find your API Key To use Planet's APIs, you'll need an API key. API keys are available to all registered users with active Planet accounts.Once you're signed up, log in to planet.com/account to get your API key. Find the API key field under your account information, as seen here: Account information (not a real API key) Registering for a Google Earth Engine Account If you don\u2019t have a developer account sign up for one here and make sure you follow the instructions to install the python CLI. The API and the CLI gets updated frequently and as does the install process as needed so you can read the latest instructions at the page. Getting Help with Planet and Google Earth Engine Both Planet and Google Earth Engine maintain a developer page for you to find out more information,test tutorials along with housing a few quick FAQ(s) You can find Planet Developer Site here and offcourse the Earth Engine Developers Page","title":"Setting up your Accounts"},{"location":"projects/rpl/#registering-for-a-planet-account","text":"What you need first to get started in simply to register for a Planet account. These account will almost immediately gain access to the Open California Dataset which is maintained regulary and is perhaps one of the largest open imagery dataset at this spatial and temporal resolution. You can find more information about the Open California project here . These datasets and full-resolution imagery for the entire state of California are covered under a CC BY-SA 4.0 license via Planet's Open California initiative. If you are a university researchers, academics, and/or scientists, your free account allows you to download 10,000 square kilometers of data for non commercial use, every month, anywhere in the world. You can apply for Education and Research account here","title":"Registering for a Planet account"},{"location":"projects/rpl/#sign-up-for-a-planet-account","text":"Planet Explorer is a powerful tool for exploring Planet's catalog of daily imagery and worldwide mosaics directly in your browser. It's also your gateway to creating a Planet Account,and gaining access to Planet's APIs.To sign up, visit planet.com/explorer and click Get Started : Get started with Planet Explorer From there, click Sign Up in the top right of your screen, and enter your email address to receive an invitation: Sign up with Planet Explorer Check your email follow the directions to complete the registration process.","title":"Sign up for a Planet Account"},{"location":"projects/rpl/#find-your-api-key","text":"To use Planet's APIs, you'll need an API key. API keys are available to all registered users with active Planet accounts.Once you're signed up, log in to planet.com/account to get your API key. Find the API key field under your account information, as seen here: Account information (not a real API key)","title":"Find your API Key"},{"location":"projects/rpl/#registering-for-a-google-earth-engine-account","text":"If you don\u2019t have a developer account sign up for one here and make sure you follow the instructions to install the python CLI. The API and the CLI gets updated frequently and as does the install process as needed so you can read the latest instructions at the page.","title":"Registering for a Google Earth Engine Account"},{"location":"projects/rpl/#getting-help-with-planet-and-google-earth-engine","text":"Both Planet and Google Earth Engine maintain a developer page for you to find out more information,test tutorials along with housing a few quick FAQ(s) You can find Planet Developer Site here and offcourse the Earth Engine Developers Page","title":"Getting Help with Planet and Google Earth Engine"}]}